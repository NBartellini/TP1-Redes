{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Archivos NLTK.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oc_Sw5MhQZiG"},"source":["A través de esta notebook, se realizó el preprocesado de NLTK guardando los archivos para optimizar el tiempo de ejecución al ejecutar el algoritmo de Multinomial Naive Bayes."]},{"cell_type":"markdown","metadata":{"id":"d6_WDrmCNbwU"},"source":["#Librerías + montar drive + dataset original"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snM8WWrSNeLH","executionInfo":{"status":"ok","timestamp":1633293148420,"user_tz":180,"elapsed":4422,"user":{"displayName":"Nicole Bartellini Huapalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQqDlbh0pzuqnEKiVpxb5_bqNuiNFERy7yS8-I1Q=s64","userId":"07239068753201303887"}},"outputId":"8b84dbb6-bd56-4747-be04-28121130f166"},"source":[" pip install dask[dataframe] --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n","Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n","Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n","Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n","Collecting fsspec>=0.6.0\n","  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 5.1 MB/s \n","\u001b[?25hCollecting partd>=0.3.10\n","  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.2)\n","Collecting locket\n","  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n","Installing collected packages: locket, partd, fsspec\n","Successfully installed fsspec-2021.10.0 locket-0.2.1 partd-1.2.0\n"]}]},{"cell_type":"code","metadata":{"id":"8M7MIq3cNmj1"},"source":["import os\n","import time\n","import numpy as np \n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import dask.dataframe as dd\n","#Para el preprocesado\n","import nltk\n","from collections import Counter\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus   import stopwords\n","from nltk.tokenize import TreebankWordTokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFSQs7_mNoSn","executionInfo":{"status":"ok","timestamp":1633293179654,"user_tz":180,"elapsed":29913,"user":{"displayName":"Nicole Bartellini Huapalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQqDlbh0pzuqnEKiVpxb5_bqNuiNFERy7yS8-I1Q=s64","userId":"07239068753201303887"}},"outputId":"638360c2-4317-4f58-e31f-274045e1cc04"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uKAeK3IXqA-","executionInfo":{"status":"ok","timestamp":1633293180689,"user_tz":180,"elapsed":1040,"user":{"displayName":"Nicole Bartellini Huapalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQqDlbh0pzuqnEKiVpxb5_bqNuiNFERy7yS8-I1Q=s64","userId":"07239068753201303887"}},"outputId":"f7b33dd1-a95a-48df-c017-ae8fc2a08132"},"source":["#Descargamos los requerimientos para utlizar las funciones\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"SKyTJiYOwyi5"},"source":["Cambie el path donde se encuentran descargado los archivos:"]},{"cell_type":"code","metadata":{"id":"-dbOZYBrCsm3"},"source":["# Cargo los datos\n","path = \"/content/drive/MyDrive/Redes TPS/TP Redes 1/\"\n","df_train = pd.read_hdf(path+\"train_data.hdf5\")\n","df_valid = pd.read_hdf(path+\"valid_data.hdf5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_v0HUX7eQLD5"},"source":["#Funciones"]},{"cell_type":"code","metadata":{"id":"Eo_HFJQSXjV3"},"source":["#Inicializamos el PorterStemmer y WordnetLemmatizer\n","tokenizer  = TreebankWordTokenizer()\n","stemmer    = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0EseZCg0vPL"},"source":["def nltk_preprocessor_callback(**kwargs):\n","    \"\"\" kwargs -> hp\n","        Preprocesamiento con NLTK igual que en la clase anterior \"\"\"\n","\n","    def preprocessor(datapoint):\n","        raw_datapoint          = datapoint\n","        tokenized_datapoint    = tokenizer.tokenize(str(raw_datapoint))\n","\n","        # Decide if we are going to lemmatize our data\n","        if kwargs.setdefault('is_lem', True):\n","            lemmatized_datapoint   = [lemmatizer.lemmatize(x,pos='v') for x in tokenized_datapoint]\n","        else:\n","            lemmatized_datapoint   = tokenized_datapoint\n","\n","        # Decide if we are going to remove stopwords our data, kwargs -> hp\n","        if kwargs.setdefault('is_stop', True):\n","            nonstop_datapoint      = [x for x in lemmatized_datapoint if x not in stopwords.words('english')]\n","        else:\n","            nonstop_datapoint      = lemmatized_datapoint\n","\n","        # Decide if we are going to apply stemming to our data, kwargs -> hp\n","        if kwargs.setdefault('is_stem', True):\n","            stemmed_datapoint      = [stemmer.stem(x) for x in nonstop_datapoint]\n","            filtered_datapoint     = stemmed_datapoint\n","        else:\n","            filtered_datapoint     = nonstop_datapoint\n","        \n","        # Skip this if not applying alpha\n","        if kwargs.setdefault('is_alpha', True):\n","            alphanumeric_datapoint = [x for x in filtered_datapoint if x.isalpha()]\n","            filtered_datapoint     = alphanumeric_datapoint\n","\n","        return ' '.join(filtered_datapoint)\n","\n","    return preprocessor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcCIVuORBMcX"},"source":["def run_nltk_preprocessor(hp, dataset=None):\n","    print('NLTK Preprocessing...')\n","    to = time.time()\n","    data = pd.DataFrame()\n","    preprocessor = nltk_preprocessor_callback(\n","            is_lem=hp['is_lem'],\n","            is_stop=hp['is_stop'],\n","            is_stem=hp['is_stem'],\n","            is_alpha=hp['is_alpha']\n","            )\n","    ddataset = dd.from_pandas(dataset, npartitions=os.cpu_count())\n","    data['text'] = ddataset['text'].map_partitions(lambda df: df.apply(preprocessor)).compute(scheduler='multiprocessing')\n","    tf = time.time()\n","    print('finished in', (int(tf-to)), 'seconds.')\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xcV92jGfNYAK"},"source":["#Procesamiento"]},{"cell_type":"markdown","metadata":{"id":"ayS4nA59NHXv"},"source":["En esta notebook se realizó el preprocesado por NLTK de cada una de las siguiente opciones:"]},{"cell_type":"code","metadata":{"id":"SUxi82gfNDo4"},"source":["#Definimos los hiperparámetros que vamos a utilizar en las transformaciones con NLTK\n","hiperparameters = {\n","    'is_lem':       [True, False], #si usa o no lematización\n","    'is_stop':      [True, False],  #si elimina o no stopwords\n","    'is_stem':      [True, False],  #si realizar o no la stemización\n","    'is_alpha':     [True, False],  #si elimina valores no alfabeticos\n","    'is_lowerc':    [True, False],  #si pasa todo a minúscula\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"Wkx2P-VdNVLl","executionInfo":{"status":"ok","timestamp":1633293188734,"user_tz":180,"elapsed":10,"user":{"displayName":"Nicole Bartellini Huapalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQqDlbh0pzuqnEKiVpxb5_bqNuiNFERy7yS8-I1Q=s64","userId":"07239068753201303887"}},"outputId":"25405376-487e-4451-e633-71150946a5fa"},"source":["reg = []\n","#lo convertimos en un dataframe, primero apilando las opciones en una lista\n","for lem_b in hiperparameters['is_lem']:\n","  for stop_b in hiperparameters['is_stop']:\n","    for stem_b in hiperparameters['is_stem']:\n","      for alpha_b in hiperparameters['is_alpha']:\n","        for lower_b in hiperparameters['is_lowerc']:\n","             reg.append([lem_b,stop_b,stem_b,alpha_b,lower_b])\n","\n","hp = pd.DataFrame(reg, columns =['is_lem', 'is_stop','is_stem','is_alpha','is_lowercase'])\n","hp.head(5) #son 32 opciones"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>is_lem</th>\n","      <th>is_stop</th>\n","      <th>is_stem</th>\n","      <th>is_alpha</th>\n","      <th>is_lowercase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   is_lem  is_stop  is_stem  is_alpha  is_lowercase\n","0    True     True     True      True          True\n","1    True     True     True      True         False\n","2    True     True     True     False          True\n","3    True     True     True     False         False\n","4    True     True    False      True          True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"qoLyvMgpSoPU"},"source":["path = '/content/drive/MyDrive/Redes TPS/TP Redes 1/NLTK data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTQfeTpaQsb9","executionInfo":{"status":"ok","timestamp":1633284263815,"user_tz":180,"elapsed":11458080,"user":{"displayName":"Nicole Bartellini Huapalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQqDlbh0pzuqnEKiVpxb5_bqNuiNFERy7yS8-I1Q=s64","userId":"07239068753201303887"}},"outputId":"e9d23874-2227-4189-f86f-da9e675783a9"},"source":["names_train=[]\n","names_valid=[]\n","for idx,hyperParam in hp.iterrows():\n","  name='X_train_NLTK'\n","  name2='X_valid_NLTK'\n","  if hyperParam['is_lem']==True:\n","    name=name+'_lem'\n","    name2=name2+'_lem'\n","  if hyperParam['is_stop']==True:\n","    name=name+'_stop'\n","    name2=name2+'_stop'\n","  if hyperParam['is_stem']==True:\n","    name=name+'_stem'\n","    name2=name2+'_stem'\n","  if hyperParam['is_alpha']==True:\n","    name=name+'_alpha'\n","    name2=name2+'_alpha'\n","  if hyperParam['is_lowercase']==True:\n","    name=name+'_lowerc'\n","    name2=name2+'_lowerc'\n","  name=name+'.csv'\n","  name2=name2+'.csv'\n","  names_train.append(name)\n","  names_valid.append(name2)\n","  #data_train = run_nltk_preprocessor(hyperParam,df_train)\n","  #data_valid = run_nltk_preprocessor(hyperParam,df_valid)\n","  #data_train.to_json(path+name)\n","  #data_valid.to_json(path+name2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NLTK Preprocessing...\n","finished in 649 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 647 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 647 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 648 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 584 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 585 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 583 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 585 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 142 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 142 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 141 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 141 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 69 seconds.\n","NLTK Preprocessing...\n","finished in 1 seconds.\n","NLTK Preprocessing...\n","finished in 69 seconds.\n","NLTK Preprocessing...\n","finished in 1 seconds.\n","NLTK Preprocessing...\n","finished in 68 seconds.\n","NLTK Preprocessing...\n","finished in 1 seconds.\n","NLTK Preprocessing...\n","finished in 68 seconds.\n","NLTK Preprocessing...\n","finished in 1 seconds.\n","NLTK Preprocessing...\n","finished in 628 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 627 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 627 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 627 seconds.\n","NLTK Preprocessing...\n","finished in 11 seconds.\n","NLTK Preprocessing...\n","finished in 557 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 556 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 558 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 560 seconds.\n","NLTK Preprocessing...\n","finished in 10 seconds.\n","NLTK Preprocessing...\n","finished in 129 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 129 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 129 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 129 seconds.\n","NLTK Preprocessing...\n","finished in 2 seconds.\n","NLTK Preprocessing...\n","finished in 49 seconds.\n","NLTK Preprocessing...\n","finished in 1 seconds.\n","NLTK Preprocessing...\n","finished in 49 seconds.\n","NLTK Preprocessing...\n","finished in 1 seconds.\n","NLTK Preprocessing...\n","finished in 48 seconds.\n","NLTK Preprocessing...\n","finished in 0 seconds.\n","NLTK Preprocessing...\n","finished in 48 seconds.\n","NLTK Preprocessing...\n","finished in 0 seconds.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"C2yKWph-cNW3","executionInfo":{"status":"ok","timestamp":1633293315836,"user_tz":180,"elapsed":5,"user":{"displayName":"Nicole Bartellini Huapalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQqDlbh0pzuqnEKiVpxb5_bqNuiNFERy7yS8-I1Q=s64","userId":"07239068753201303887"}},"outputId":"0af550f6-8ec1-4c43-823d-71893e412fd1"},"source":["hp['X_train']=names_train\n","hp['X_valid']=names_valid\n","hp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>is_lem</th>\n","      <th>is_stop</th>\n","      <th>is_stem</th>\n","      <th>is_alpha</th>\n","      <th>is_lowercase</th>\n","      <th>X_train</th>\n","      <th>X_valid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_stop_stem_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_stop_stem_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_stop_stem_alpha.csv</td>\n","      <td>X_valid_NLTK_lem_stop_stem_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_stop_stem_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_stop_stem_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_stop_stem.csv</td>\n","      <td>X_valid_NLTK_lem_stop_stem.csv</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_stop_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_stop_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_stop_alpha.csv</td>\n","      <td>X_valid_NLTK_lem_stop_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_stop_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_stop_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_stop.csv</td>\n","      <td>X_valid_NLTK_lem_stop.csv</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_stem_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_stem_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_stem_alpha.csv</td>\n","      <td>X_valid_NLTK_lem_stem_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_stem_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_stem_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_stem.csv</td>\n","      <td>X_valid_NLTK_lem_stem.csv</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem_alpha.csv</td>\n","      <td>X_valid_NLTK_lem_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lem_lowerc.csv</td>\n","      <td>X_valid_NLTK_lem_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_lem.csv</td>\n","      <td>X_valid_NLTK_lem.csv</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_stop_stem_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_stop_stem_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_stop_stem_alpha.csv</td>\n","      <td>X_valid_NLTK_stop_stem_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_stop_stem_lowerc.csv</td>\n","      <td>X_valid_NLTK_stop_stem_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_stop_stem.csv</td>\n","      <td>X_valid_NLTK_stop_stem.csv</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_stop_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_stop_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_stop_alpha.csv</td>\n","      <td>X_valid_NLTK_stop_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_stop_lowerc.csv</td>\n","      <td>X_valid_NLTK_stop_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_stop.csv</td>\n","      <td>X_valid_NLTK_stop.csv</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_stem_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_stem_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_stem_alpha.csv</td>\n","      <td>X_valid_NLTK_stem_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_stem_lowerc.csv</td>\n","      <td>X_valid_NLTK_stem_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_stem.csv</td>\n","      <td>X_valid_NLTK_stem.csv</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_alpha_lowerc.csv</td>\n","      <td>X_valid_NLTK_alpha_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>X_train_NLTK_alpha.csv</td>\n","      <td>X_valid_NLTK_alpha.csv</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>X_train_NLTK_lowerc.csv</td>\n","      <td>X_valid_NLTK_lowerc.csv</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>X_train_NLTK.csv</td>\n","      <td>X_valid_NLTK.csv</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    is_lem  ...                                      X_valid\n","0     True  ...  X_valid_NLTK_lem_stop_stem_alpha_lowerc.csv\n","1     True  ...         X_valid_NLTK_lem_stop_stem_alpha.csv\n","2     True  ...        X_valid_NLTK_lem_stop_stem_lowerc.csv\n","3     True  ...               X_valid_NLTK_lem_stop_stem.csv\n","4     True  ...       X_valid_NLTK_lem_stop_alpha_lowerc.csv\n","5     True  ...              X_valid_NLTK_lem_stop_alpha.csv\n","6     True  ...             X_valid_NLTK_lem_stop_lowerc.csv\n","7     True  ...                    X_valid_NLTK_lem_stop.csv\n","8     True  ...       X_valid_NLTK_lem_stem_alpha_lowerc.csv\n","9     True  ...              X_valid_NLTK_lem_stem_alpha.csv\n","10    True  ...             X_valid_NLTK_lem_stem_lowerc.csv\n","11    True  ...                    X_valid_NLTK_lem_stem.csv\n","12    True  ...            X_valid_NLTK_lem_alpha_lowerc.csv\n","13    True  ...                   X_valid_NLTK_lem_alpha.csv\n","14    True  ...                  X_valid_NLTK_lem_lowerc.csv\n","15    True  ...                         X_valid_NLTK_lem.csv\n","16   False  ...      X_valid_NLTK_stop_stem_alpha_lowerc.csv\n","17   False  ...             X_valid_NLTK_stop_stem_alpha.csv\n","18   False  ...            X_valid_NLTK_stop_stem_lowerc.csv\n","19   False  ...                   X_valid_NLTK_stop_stem.csv\n","20   False  ...           X_valid_NLTK_stop_alpha_lowerc.csv\n","21   False  ...                  X_valid_NLTK_stop_alpha.csv\n","22   False  ...                 X_valid_NLTK_stop_lowerc.csv\n","23   False  ...                        X_valid_NLTK_stop.csv\n","24   False  ...           X_valid_NLTK_stem_alpha_lowerc.csv\n","25   False  ...                  X_valid_NLTK_stem_alpha.csv\n","26   False  ...                 X_valid_NLTK_stem_lowerc.csv\n","27   False  ...                        X_valid_NLTK_stem.csv\n","28   False  ...                X_valid_NLTK_alpha_lowerc.csv\n","29   False  ...                       X_valid_NLTK_alpha.csv\n","30   False  ...                      X_valid_NLTK_lowerc.csv\n","31   False  ...                             X_valid_NLTK.csv\n","\n","[32 rows x 7 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"X8UQraOYUUvE"},"source":["hp.to_csv(path+'get_namefile.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hA8SugI6dMJY"},"source":[""],"execution_count":null,"outputs":[]}]}