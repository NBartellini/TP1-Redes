{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "p5nM7mK0hPWC",
   "metadata": {
    "id": "p5nM7mK0hPWC"
   },
   "source": [
    "# Condiciones de entrega\n",
    "\n",
    "\n",
    "Además de realizar al menos un envío replicando los resultados del paper antes mencionados, se deberá entregar el código del trabajo práctico junto a un breve informe que explique la idea del modelo implementado y una indicación de cómo ejecutar el programa si fuera necesaria. Ambos elementos se deben subir a un repositorio en github y enviar el link vìa campus. El trabajo podrá hacerse en grupos de hasta 3 personas. Los integrantes deben estar registrados enviando mail a cselmo@itba.edu.ar\n",
    "\n",
    "# Fecha de entrega del TP\n",
    "\n",
    "\n",
    "Para la evaluaciòn del TP como tal la fecha de vencimiento es el 27 de septiembre a las 23:59hs. Para dicha fecha deberán resolver el problema utilizando un clasificador de texto basado en Naive Bayes Multinomial y otro en MLP. La estructura de validación debe quedar perfectamente clara en el informe (Hold-out Validation, K-folding, etc).\n",
    "\n",
    "# Para la evaluación del TP se debe informar claramente:\n",
    "\n",
    "1) Técnica de validación utilizada. La metodología con respecto a este punto debe ser impecable.\n",
    "\n",
    "2) Elección de una métrica primaria\n",
    "\n",
    "3) Informar las métricas secundarias: Precision, Recall, F1-Score y ROC-AUC, explicando claramente qué mide cada una de ellas, sus ventajas y desventajas.\n",
    "\n",
    "4) Para las métricas mencionadas anteriormente realizar una interpretaciòn y comparación para el modelo NBMN y MLP.\n",
    "\n",
    "5) En las conclusiones informar si el dataset posee o no sesgos en el armado de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcd896-948d-4a73-9522-5181e2a9801d",
   "metadata": {
    "id": "edbcd896-948d-4a73-9522-5181e2a9801d"
   },
   "source": [
    "# Librerías utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "M7VgECjb-k9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4614,
     "status": "ok",
     "timestamp": 1633386065109,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "M7VgECjb-k9b",
    "outputId": "33d62b0c-b8e0-434a-c52d-da94b1cf6c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.2)\n",
      "Collecting locket\n",
      "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n",
      "Installing collected packages: locket, partd, fsspec\n",
      "Successfully installed fsspec-2021.10.0 locket-0.2.1 partd-1.2.0\n"
     ]
    }
   ],
   "source": [
    " pip install dask[dataframe] --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761cb712-9bc6-4893-914d-444f570f4fc2",
   "metadata": {
    "executionInfo": {
     "elapsed": 1913,
     "status": "ok",
     "timestamp": 1633386068901,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "761cb712-9bc6-4893-914d-444f570f4fc2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#Para el preprocesado\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Para los modelos\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540cfa0-c12e-430f-97f6-8827e99a81e6",
   "metadata": {
    "id": "7540cfa0-c12e-430f-97f6-8827e99a81e6"
   },
   "source": [
    "# Importamos los datos de la competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rVNIgrpkCorM",
   "metadata": {
    "id": "rVNIgrpkCorM"
   },
   "source": [
    "# Cargar datos desde la carpeta de drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hfojDfv5ZjuE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28044,
     "status": "ok",
     "timestamp": 1633386100616,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "hfojDfv5ZjuE",
    "outputId": "f155c069-b277-48b9-93af-3ad1f9423c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-dbOZYBrCsm3",
   "metadata": {
    "executionInfo": {
     "elapsed": 7940,
     "status": "ok",
     "timestamp": 1633386110499,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "-dbOZYBrCsm3"
   },
   "outputs": [],
   "source": [
    "# Cargo los datos\n",
    "df_train = pd.read_hdf(\"/content/drive/MyDrive/Redes TPS/TP Redes 1/train_data.hdf5\")\n",
    "df_valid = pd.read_hdf(\"/content/drive/MyDrive/Redes TPS/TP Redes 1/valid_data.hdf5\")\n",
    "df_test = pd.read_hdf(\"/content/drive/MyDrive/Redes TPS/TP Redes 1/test_data.hdf5\")\n",
    "df_submission = pd.read_csv(\"/content/drive/MyDrive/Redes TPS/TP Redes 1/submission_sample.csv\", index_col=\"pairID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3MpZgsE8EzIs",
   "metadata": {
    "id": "3MpZgsE8EzIs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "zDL_DPspdfc7",
   "metadata": {
    "id": "zDL_DPspdfc7"
   },
   "source": [
    "### Vamos a generar un modelo con MLPClassifier de Scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZNeNCoV1duQ_",
   "metadata": {
    "id": "ZNeNCoV1duQ_"
   },
   "source": [
    "Esto genera un Multiple Layer Percepron a partir de diferentes parámetros, como cantidad de capas ocultas, función de activación, entre otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gwdlNpz5dtCe",
   "metadata": {
    "id": "gwdlNpz5dtCe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sTWUhaIxgZrK",
   "metadata": {
    "id": "sTWUhaIxgZrK"
   },
   "source": [
    "## Verificamos la variabilidad de los resultados \n",
    "\n",
    "* dependiendo de la partición del conjunto de entrenamiento y validación \n",
    "* con el modelo MLPClassifier de Scikit Learn\n",
    "\n",
    "Solo para comprobar, vamos a juntar en un mismo dataframe validación y entrenamiento para realizar 3 particiones de ese dataset total y verificar que los resultados del modelo no varíen demasiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "BAGmt4fh1cdI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1633261489141,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "BAGmt4fh1cdI",
    "outputId": "698a8d11-16c4-4c01-a92e-95df67923cb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg#0r1c</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>they are inside of a house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg#0r1e</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two guys are in a yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg#0r1n</th>\n",
       "      <td>neutral</td>\n",
       "      <td>They are doing yardwork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg#1r1c</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A man is swimming.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg#1r1e</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Two young white men are near some bushes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985982384.jpg#3r1e</th>\n",
       "      <td>entailment</td>\n",
       "      <td>The men and women are dressed in clothes for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985982384.jpg#3r1n</th>\n",
       "      <td>neutral</td>\n",
       "      <td>The bathing suits are blue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98756067.jpg#1r1c</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Two men trying to dance for a song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98756067.jpg#1r1e</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Few men practicing martial arts in a studio, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98756067.jpg#1r1n</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Two men practicing martial arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        gold_label                                               text\n",
       "pairID                                                                               \n",
       "1000092795.jpg#0r1c  contradiction                         they are inside of a house\n",
       "1000092795.jpg#0r1e     entailment                             two guys are in a yard\n",
       "1000092795.jpg#0r1n        neutral                            They are doing yardwork\n",
       "1000092795.jpg#1r1c  contradiction                                 A man is swimming.\n",
       "1000092795.jpg#1r1e     entailment          Two young white men are near some bushes.\n",
       "...                            ...                                                ...\n",
       "985982384.jpg#3r1e      entailment  The men and women are dressed in clothes for t...\n",
       "985982384.jpg#3r1n         neutral                        The bathing suits are blue.\n",
       "98756067.jpg#1r1c    contradiction                 Two men trying to dance for a song\n",
       "98756067.jpg#1r1e       entailment  Few men practicing martial arts in a studio, w...\n",
       "98756067.jpg#1r1n       entailment                    Two men practicing martial arts\n",
       "\n",
       "[559209 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df_train, df_valid])\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oKKIfdoJ4yCB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1014051,
     "status": "ok",
     "timestamp": 1633264924141,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "oKKIfdoJ4yCB",
    "outputId": "86390599-ee82-4fce-f036-369c4e8b4552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.94211418\n",
      "Iteration 2, loss = 0.84715580\n",
      "Iteration 3, loss = 0.83762450\n",
      "Iteration 4, loss = 0.83114652\n",
      "Iteration 5, loss = 0.82556079\n",
      "Iteration 6, loss = 0.82108821\n",
      "Iteration 7, loss = 0.81706696\n",
      "Iteration 8, loss = 0.81383148\n",
      "Iteration 9, loss = 0.81114776\n",
      "Iteration 10, loss = 0.80851843\n",
      "Iteration 11, loss = 0.80632272\n",
      "Iteration 12, loss = 0.80435895\n",
      "Iteration 13, loss = 0.80274059\n",
      "Iteration 14, loss = 0.80135207\n",
      "Iteration 15, loss = 0.79991097\n",
      "Iteration 16, loss = 0.79863763\n",
      "Iteration 17, loss = 0.79767120\n",
      "Iteration 18, loss = 0.79651151\n",
      "Iteration 19, loss = 0.79565920\n",
      "Iteration 20, loss = 0.79484816\n",
      "Iteration 21, loss = 0.79391581\n",
      "Iteration 22, loss = 0.79328918\n",
      "Iteration 23, loss = 0.79268005\n",
      "Iteration 24, loss = 0.79211675\n",
      "Iteration 25, loss = 0.79138993\n",
      "Iteration 26, loss = 0.79078668\n",
      "Iteration 27, loss = 0.79020667\n",
      "Iteration 28, loss = 0.78974181\n",
      "Iteration 29, loss = 0.78930633\n",
      "Iteration 30, loss = 0.78884599\n",
      "Iteration 31, loss = 0.78836869\n",
      "Iteration 32, loss = 0.78800329\n",
      "Iteration 33, loss = 0.78749078\n",
      "Iteration 34, loss = 0.78725641\n",
      "Iteration 35, loss = 0.78692175\n",
      "Iteration 36, loss = 0.78651631\n",
      "Iteration 37, loss = 0.78616300\n",
      "Iteration 38, loss = 0.78595462\n",
      "Iteration 39, loss = 0.78569953\n",
      "Iteration 40, loss = 0.78534988\n",
      "Iteration 41, loss = 0.78499662\n",
      "Iteration 42, loss = 0.78481620\n",
      "Iteration 43, loss = 0.78440822\n",
      "Iteration 44, loss = 0.78438505\n",
      "Iteration 45, loss = 0.78394019\n",
      "Iteration 46, loss = 0.78388809\n",
      "Iteration 47, loss = 0.78350416\n",
      "Iteration 48, loss = 0.78343480\n",
      "Iteration 49, loss = 0.78315811\n",
      "Iteration 50, loss = 0.78282006\n",
      "Iteration 51, loss = 0.78284001\n",
      "Iteration 52, loss = 0.78260740\n",
      "Iteration 53, loss = 0.78225582\n",
      "Iteration 54, loss = 0.78204003\n",
      "Iteration 55, loss = 0.78199516\n",
      "Iteration 56, loss = 0.78171128\n",
      "Iteration 57, loss = 0.78173093\n",
      "Iteration 58, loss = 0.78138102\n",
      "Iteration 59, loss = 0.78131072\n",
      "Iteration 60, loss = 0.78112445\n",
      "Iteration 61, loss = 0.78093825\n",
      "Iteration 62, loss = 0.78081267\n",
      "Iteration 63, loss = 0.78066752\n",
      "Iteration 64, loss = 0.78059194\n",
      "Iteration 65, loss = 0.78028001\n",
      "Iteration 66, loss = 0.78023027\n",
      "Iteration 67, loss = 0.78019593\n",
      "Iteration 68, loss = 0.77992538\n",
      "Iteration 69, loss = 0.77991788\n",
      "Iteration 70, loss = 0.77967996\n",
      "Iteration 71, loss = 0.77949626\n",
      "Iteration 72, loss = 0.77954434\n",
      "Iteration 73, loss = 0.77921156\n",
      "Iteration 74, loss = 0.77917588\n",
      "Iteration 75, loss = 0.77909503\n",
      "Iteration 76, loss = 0.77906873\n",
      "Iteration 77, loss = 0.77877652\n",
      "Iteration 78, loss = 0.77884161\n",
      "Iteration 79, loss = 0.77854719\n",
      "Iteration 80, loss = 0.77848833\n",
      "Iteration 81, loss = 0.77854206\n",
      "Iteration 82, loss = 0.77829162\n",
      "Iteration 83, loss = 0.77819539\n",
      "Iteration 84, loss = 0.77823574\n",
      "Iteration 85, loss = 0.77807867\n",
      "Iteration 86, loss = 0.77783800\n",
      "Iteration 87, loss = 0.77788371\n",
      "Iteration 88, loss = 0.77767848\n",
      "Iteration 89, loss = 0.77757398\n",
      "Iteration 90, loss = 0.77759028\n",
      "Iteration 91, loss = 0.77758337\n",
      "Iteration 92, loss = 0.77737323\n",
      "Iteration 93, loss = 0.77733545\n",
      "Iteration 94, loss = 0.77720957\n",
      "Iteration 95, loss = 0.77707789\n",
      "Iteration 96, loss = 0.77720948\n",
      "Iteration 97, loss = 0.77699957\n",
      "Iteration 98, loss = 0.77692198\n",
      "Iteration 99, loss = 0.77678749\n",
      "Iteration 100, loss = 0.77674302\n",
      "Iteration 101, loss = 0.77654964\n",
      "Iteration 102, loss = 0.77648485\n",
      "Iteration 103, loss = 0.77654234\n",
      "Iteration 104, loss = 0.77646130\n",
      "Iteration 105, loss = 0.77638334\n",
      "Iteration 106, loss = 0.77623978\n",
      "Iteration 107, loss = 0.77628304\n",
      "Iteration 108, loss = 0.77631243\n",
      "Iteration 109, loss = 0.77610704\n",
      "Iteration 110, loss = 0.77603612\n",
      "Iteration 111, loss = 0.77604941\n",
      "Iteration 112, loss = 0.77596028\n",
      "Iteration 113, loss = 0.77591856\n",
      "Iteration 114, loss = 0.77588248\n",
      "Iteration 115, loss = 0.77573365\n",
      "Iteration 116, loss = 0.77568370\n",
      "Iteration 117, loss = 0.77568707\n",
      "Iteration 118, loss = 0.77565355\n",
      "Iteration 119, loss = 0.77550604\n",
      "Iteration 120, loss = 0.77537886\n",
      "Iteration 121, loss = 0.77540706\n",
      "Iteration 122, loss = 0.77531561\n",
      "Iteration 123, loss = 0.77526304\n",
      "Iteration 124, loss = 0.77526799\n",
      "Iteration 125, loss = 0.77511487\n",
      "Iteration 126, loss = 0.77515307\n",
      "Iteration 127, loss = 0.77504192\n",
      "Iteration 128, loss = 0.77497860\n",
      "Iteration 129, loss = 0.77488886\n",
      "Iteration 130, loss = 0.77500540\n",
      "Iteration 131, loss = 0.77477620\n",
      "Iteration 132, loss = 0.77479158\n",
      "Iteration 133, loss = 0.77483118\n",
      "Iteration 134, loss = 0.77455951\n",
      "Iteration 135, loss = 0.77462085\n",
      "Iteration 136, loss = 0.77464752\n",
      "Iteration 137, loss = 0.77442551\n",
      "Iteration 138, loss = 0.77440805\n",
      "Iteration 139, loss = 0.77440262\n",
      "Iteration 140, loss = 0.77429050\n",
      "Iteration 141, loss = 0.77422355\n",
      "Iteration 142, loss = 0.77426748\n",
      "Iteration 143, loss = 0.77419921\n",
      "Iteration 144, loss = 0.77425211\n",
      "Iteration 145, loss = 0.77419392\n",
      "Iteration 146, loss = 0.77398469\n",
      "Iteration 147, loss = 0.77393960\n",
      "Iteration 148, loss = 0.77394595\n",
      "Iteration 149, loss = 0.77389229\n",
      "Iteration 150, loss = 0.77380011\n",
      "Iteration 151, loss = 0.77375239\n",
      "Iteration 152, loss = 0.77371519\n",
      "Iteration 153, loss = 0.77371937\n",
      "Iteration 154, loss = 0.77371048\n",
      "Iteration 155, loss = 0.77351974\n",
      "Iteration 156, loss = 0.77347881\n",
      "Iteration 157, loss = 0.77355240\n",
      "Iteration 158, loss = 0.77338709\n",
      "Iteration 159, loss = 0.77341171\n",
      "Iteration 160, loss = 0.77335638\n",
      "Iteration 161, loss = 0.77330491\n",
      "Iteration 162, loss = 0.77330771\n",
      "Iteration 163, loss = 0.77324439\n",
      "Iteration 164, loss = 0.77318303\n",
      "Iteration 165, loss = 0.77304822\n",
      "Iteration 166, loss = 0.77305795\n",
      "Iteration 167, loss = 0.77303984\n",
      "Iteration 168, loss = 0.77303107\n",
      "Iteration 169, loss = 0.77300384\n",
      "Iteration 170, loss = 0.77298591\n",
      "Iteration 171, loss = 0.77280979\n",
      "Iteration 172, loss = 0.77282321\n",
      "Iteration 173, loss = 0.77283650\n",
      "Iteration 174, loss = 0.77282462\n",
      "Iteration 175, loss = 0.77267833\n",
      "Iteration 176, loss = 0.77271067\n",
      "Iteration 177, loss = 0.77273637\n",
      "Iteration 178, loss = 0.77264725\n",
      "Iteration 179, loss = 0.77263893\n",
      "Iteration 180, loss = 0.77266854\n",
      "Iteration 181, loss = 0.77249197\n",
      "Iteration 182, loss = 0.77254495\n",
      "Iteration 183, loss = 0.77242761\n",
      "Iteration 184, loss = 0.77235354\n",
      "Iteration 185, loss = 0.77237991\n",
      "Iteration 186, loss = 0.77239070\n",
      "Iteration 187, loss = 0.77229396\n",
      "Iteration 188, loss = 0.77224763\n",
      "Iteration 189, loss = 0.77218489\n",
      "Iteration 190, loss = 0.77218388\n",
      "Iteration 191, loss = 0.77216635\n",
      "Iteration 192, loss = 0.77217042\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91944345\n",
      "Iteration 2, loss = 0.84720145\n",
      "Iteration 3, loss = 0.83988623\n",
      "Iteration 4, loss = 0.83459372\n",
      "Iteration 5, loss = 0.83014228\n",
      "Iteration 6, loss = 0.82621284\n",
      "Iteration 7, loss = 0.82275927\n",
      "Iteration 8, loss = 0.81949236\n",
      "Iteration 9, loss = 0.81660272\n",
      "Iteration 10, loss = 0.81377254\n",
      "Iteration 11, loss = 0.81130050\n",
      "Iteration 12, loss = 0.80872560\n",
      "Iteration 13, loss = 0.80660083\n",
      "Iteration 14, loss = 0.80472064\n",
      "Iteration 15, loss = 0.80303431\n",
      "Iteration 16, loss = 0.80153230\n",
      "Iteration 17, loss = 0.80011696\n",
      "Iteration 18, loss = 0.79885277\n",
      "Iteration 19, loss = 0.79788715\n",
      "Iteration 20, loss = 0.79691885\n",
      "Iteration 21, loss = 0.79581648\n",
      "Iteration 22, loss = 0.79518765\n",
      "Iteration 23, loss = 0.79437315\n",
      "Iteration 24, loss = 0.79363212\n",
      "Iteration 25, loss = 0.79302630\n",
      "Iteration 26, loss = 0.79230509\n",
      "Iteration 27, loss = 0.79172610\n",
      "Iteration 28, loss = 0.79105526\n",
      "Iteration 29, loss = 0.79067808\n",
      "Iteration 30, loss = 0.79012361\n",
      "Iteration 31, loss = 0.78968868\n",
      "Iteration 32, loss = 0.78919923\n",
      "Iteration 33, loss = 0.78890715\n",
      "Iteration 34, loss = 0.78850564\n",
      "Iteration 35, loss = 0.78811953\n",
      "Iteration 36, loss = 0.78783419\n",
      "Iteration 37, loss = 0.78763693\n",
      "Iteration 38, loss = 0.78725953\n",
      "Iteration 39, loss = 0.78700095\n",
      "Iteration 40, loss = 0.78669220\n",
      "Iteration 41, loss = 0.78634493\n",
      "Iteration 42, loss = 0.78611245\n",
      "Iteration 43, loss = 0.78576699\n",
      "Iteration 44, loss = 0.78561484\n",
      "Iteration 45, loss = 0.78538935\n",
      "Iteration 46, loss = 0.78501800\n",
      "Iteration 47, loss = 0.78489415\n",
      "Iteration 48, loss = 0.78454071\n",
      "Iteration 49, loss = 0.78448375\n",
      "Iteration 50, loss = 0.78421742\n",
      "Iteration 51, loss = 0.78399724\n",
      "Iteration 52, loss = 0.78379634\n",
      "Iteration 53, loss = 0.78365903\n",
      "Iteration 54, loss = 0.78340452\n",
      "Iteration 55, loss = 0.78320617\n",
      "Iteration 56, loss = 0.78309397\n",
      "Iteration 57, loss = 0.78288067\n",
      "Iteration 58, loss = 0.78270982\n",
      "Iteration 59, loss = 0.78257791\n",
      "Iteration 60, loss = 0.78249815\n",
      "Iteration 61, loss = 0.78234557\n",
      "Iteration 62, loss = 0.78228912\n",
      "Iteration 63, loss = 0.78203093\n",
      "Iteration 64, loss = 0.78189448\n",
      "Iteration 65, loss = 0.78164920\n",
      "Iteration 66, loss = 0.78156343\n",
      "Iteration 67, loss = 0.78167934\n",
      "Iteration 68, loss = 0.78129416\n",
      "Iteration 69, loss = 0.78123109\n",
      "Iteration 70, loss = 0.78115988\n",
      "Iteration 71, loss = 0.78096807\n",
      "Iteration 72, loss = 0.78087626\n",
      "Iteration 73, loss = 0.78072140\n",
      "Iteration 74, loss = 0.78056631\n",
      "Iteration 75, loss = 0.78053073\n",
      "Iteration 76, loss = 0.78041371\n",
      "Iteration 77, loss = 0.78038226\n",
      "Iteration 78, loss = 0.78022212\n",
      "Iteration 79, loss = 0.78010826\n",
      "Iteration 80, loss = 0.78004846\n",
      "Iteration 81, loss = 0.78002878\n",
      "Iteration 82, loss = 0.77982318\n",
      "Iteration 83, loss = 0.77971209\n",
      "Iteration 84, loss = 0.77959130\n",
      "Iteration 85, loss = 0.77958823\n",
      "Iteration 86, loss = 0.77949215\n",
      "Iteration 87, loss = 0.77932933\n",
      "Iteration 88, loss = 0.77929933\n",
      "Iteration 89, loss = 0.77919169\n",
      "Iteration 90, loss = 0.77913224\n",
      "Iteration 91, loss = 0.77900042\n",
      "Iteration 92, loss = 0.77883105\n",
      "Iteration 93, loss = 0.77896349\n",
      "Iteration 94, loss = 0.77869769\n",
      "Iteration 95, loss = 0.77879641\n",
      "Iteration 96, loss = 0.77859377\n",
      "Iteration 97, loss = 0.77855293\n",
      "Iteration 98, loss = 0.77851567\n",
      "Iteration 99, loss = 0.77838395\n",
      "Iteration 100, loss = 0.77836564\n",
      "Iteration 101, loss = 0.77820993\n",
      "Iteration 102, loss = 0.77811706\n",
      "Iteration 103, loss = 0.77805400\n",
      "Iteration 104, loss = 0.77794799\n",
      "Iteration 105, loss = 0.77789398\n",
      "Iteration 106, loss = 0.77792513\n",
      "Iteration 107, loss = 0.77775954\n",
      "Iteration 108, loss = 0.77779259\n",
      "Iteration 109, loss = 0.77775633\n",
      "Iteration 110, loss = 0.77772733\n",
      "Iteration 111, loss = 0.77764029\n",
      "Iteration 112, loss = 0.77764981\n",
      "Iteration 113, loss = 0.77736898\n",
      "Iteration 114, loss = 0.77731775\n",
      "Iteration 115, loss = 0.77732132\n",
      "Iteration 116, loss = 0.77721385\n",
      "Iteration 117, loss = 0.77721647\n",
      "Iteration 118, loss = 0.77713997\n",
      "Iteration 119, loss = 0.77712066\n",
      "Iteration 120, loss = 0.77712020\n",
      "Iteration 121, loss = 0.77706002\n",
      "Iteration 122, loss = 0.77699383\n",
      "Iteration 123, loss = 0.77683288\n",
      "Iteration 124, loss = 0.77682247\n",
      "Iteration 125, loss = 0.77678720\n",
      "Iteration 126, loss = 0.77667828\n",
      "Iteration 127, loss = 0.77665641\n",
      "Iteration 128, loss = 0.77654236\n",
      "Iteration 129, loss = 0.77657104\n",
      "Iteration 130, loss = 0.77645254\n",
      "Iteration 131, loss = 0.77649195\n",
      "Iteration 132, loss = 0.77647645\n",
      "Iteration 133, loss = 0.77638064\n",
      "Iteration 134, loss = 0.77630044\n",
      "Iteration 135, loss = 0.77614748\n",
      "Iteration 136, loss = 0.77610265\n",
      "Iteration 137, loss = 0.77610544\n",
      "Iteration 138, loss = 0.77601395\n",
      "Iteration 139, loss = 0.77603764\n",
      "Iteration 140, loss = 0.77592486\n",
      "Iteration 141, loss = 0.77590645\n",
      "Iteration 142, loss = 0.77586903\n",
      "Iteration 143, loss = 0.77591942\n",
      "Iteration 144, loss = 0.77575912\n",
      "Iteration 145, loss = 0.77567425\n",
      "Iteration 146, loss = 0.77577364\n",
      "Iteration 147, loss = 0.77565166\n",
      "Iteration 148, loss = 0.77575369\n",
      "Iteration 149, loss = 0.77557977\n",
      "Iteration 150, loss = 0.77564231\n",
      "Iteration 151, loss = 0.77544882\n",
      "Iteration 152, loss = 0.77544255\n",
      "Iteration 153, loss = 0.77535105\n",
      "Iteration 154, loss = 0.77532502\n",
      "Iteration 155, loss = 0.77527391\n",
      "Iteration 156, loss = 0.77512732\n",
      "Iteration 157, loss = 0.77520277\n",
      "Iteration 158, loss = 0.77526341\n",
      "Iteration 159, loss = 0.77512483\n",
      "Iteration 160, loss = 0.77506376\n",
      "Iteration 161, loss = 0.77500862\n",
      "Iteration 162, loss = 0.77502350\n",
      "Iteration 163, loss = 0.77495986\n",
      "Iteration 164, loss = 0.77486322\n",
      "Iteration 165, loss = 0.77492589\n",
      "Iteration 166, loss = 0.77479085\n",
      "Iteration 167, loss = 0.77489746\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.93608497\n",
      "Iteration 2, loss = 0.84636183\n",
      "Iteration 3, loss = 0.83788478\n",
      "Iteration 4, loss = 0.83227733\n",
      "Iteration 5, loss = 0.82827005\n",
      "Iteration 6, loss = 0.82486690\n",
      "Iteration 7, loss = 0.82197561\n",
      "Iteration 8, loss = 0.81929346\n",
      "Iteration 9, loss = 0.81688118\n",
      "Iteration 10, loss = 0.81446633\n",
      "Iteration 11, loss = 0.81211934\n",
      "Iteration 12, loss = 0.81000843\n",
      "Iteration 13, loss = 0.80796696\n",
      "Iteration 14, loss = 0.80609493\n",
      "Iteration 15, loss = 0.80435020\n",
      "Iteration 16, loss = 0.80278998\n",
      "Iteration 17, loss = 0.80139376\n",
      "Iteration 18, loss = 0.80009303\n",
      "Iteration 19, loss = 0.79903728\n",
      "Iteration 20, loss = 0.79781212\n",
      "Iteration 21, loss = 0.79697213\n",
      "Iteration 22, loss = 0.79599253\n",
      "Iteration 23, loss = 0.79524749\n",
      "Iteration 24, loss = 0.79454524\n",
      "Iteration 25, loss = 0.79364359\n",
      "Iteration 26, loss = 0.79313940\n",
      "Iteration 27, loss = 0.79249416\n",
      "Iteration 28, loss = 0.79200248\n",
      "Iteration 29, loss = 0.79133654\n",
      "Iteration 30, loss = 0.79084214\n",
      "Iteration 31, loss = 0.79042351\n",
      "Iteration 32, loss = 0.78988438\n",
      "Iteration 33, loss = 0.78940834\n",
      "Iteration 34, loss = 0.78894511\n",
      "Iteration 35, loss = 0.78860566\n",
      "Iteration 36, loss = 0.78812778\n",
      "Iteration 37, loss = 0.78764548\n",
      "Iteration 38, loss = 0.78758266\n",
      "Iteration 39, loss = 0.78713034\n",
      "Iteration 40, loss = 0.78677756\n",
      "Iteration 41, loss = 0.78645030\n",
      "Iteration 42, loss = 0.78633339\n",
      "Iteration 43, loss = 0.78602076\n",
      "Iteration 44, loss = 0.78574926\n",
      "Iteration 45, loss = 0.78549396\n",
      "Iteration 46, loss = 0.78524963\n",
      "Iteration 47, loss = 0.78511310\n",
      "Iteration 48, loss = 0.78496242\n",
      "Iteration 49, loss = 0.78453294\n",
      "Iteration 50, loss = 0.78430911\n",
      "Iteration 51, loss = 0.78422391\n",
      "Iteration 52, loss = 0.78391291\n",
      "Iteration 53, loss = 0.78376951\n",
      "Iteration 54, loss = 0.78369374\n",
      "Iteration 55, loss = 0.78347957\n",
      "Iteration 56, loss = 0.78327383\n",
      "Iteration 57, loss = 0.78310970\n",
      "Iteration 58, loss = 0.78299996\n",
      "Iteration 59, loss = 0.78273645\n",
      "Iteration 60, loss = 0.78279593\n",
      "Iteration 61, loss = 0.78252758\n",
      "Iteration 62, loss = 0.78231507\n",
      "Iteration 63, loss = 0.78226429\n",
      "Iteration 64, loss = 0.78202476\n",
      "Iteration 65, loss = 0.78188533\n",
      "Iteration 66, loss = 0.78184677\n",
      "Iteration 67, loss = 0.78171009\n",
      "Iteration 68, loss = 0.78159711\n",
      "Iteration 69, loss = 0.78150092\n",
      "Iteration 70, loss = 0.78129421\n",
      "Iteration 71, loss = 0.78119751\n",
      "Iteration 72, loss = 0.78109163\n",
      "Iteration 73, loss = 0.78090648\n",
      "Iteration 74, loss = 0.78091617\n",
      "Iteration 75, loss = 0.78074610\n",
      "Iteration 76, loss = 0.78075637\n",
      "Iteration 77, loss = 0.78052592\n",
      "Iteration 78, loss = 0.78037686\n",
      "Iteration 79, loss = 0.78032400\n",
      "Iteration 80, loss = 0.78031437\n",
      "Iteration 81, loss = 0.78007591\n",
      "Iteration 82, loss = 0.77992794\n",
      "Iteration 83, loss = 0.77988077\n",
      "Iteration 84, loss = 0.77984554\n",
      "Iteration 85, loss = 0.77966468\n",
      "Iteration 86, loss = 0.77964892\n",
      "Iteration 87, loss = 0.77946825\n",
      "Iteration 88, loss = 0.77947060\n",
      "Iteration 89, loss = 0.77937029\n",
      "Iteration 90, loss = 0.77930434\n",
      "Iteration 91, loss = 0.77913013\n",
      "Iteration 92, loss = 0.77903053\n",
      "Iteration 93, loss = 0.77896864\n",
      "Iteration 94, loss = 0.77891582\n",
      "Iteration 95, loss = 0.77879447\n",
      "Iteration 96, loss = 0.77873330\n",
      "Iteration 97, loss = 0.77873335\n",
      "Iteration 98, loss = 0.77873056\n",
      "Iteration 99, loss = 0.77860048\n",
      "Iteration 100, loss = 0.77856091\n",
      "Iteration 101, loss = 0.77837896\n",
      "Iteration 102, loss = 0.77834300\n",
      "Iteration 103, loss = 0.77834366\n",
      "Iteration 104, loss = 0.77819315\n",
      "Iteration 105, loss = 0.77801816\n",
      "Iteration 106, loss = 0.77802801\n",
      "Iteration 107, loss = 0.77796197\n",
      "Iteration 108, loss = 0.77788248\n",
      "Iteration 109, loss = 0.77781912\n",
      "Iteration 110, loss = 0.77774746\n",
      "Iteration 111, loss = 0.77763502\n",
      "Iteration 112, loss = 0.77774636\n",
      "Iteration 113, loss = 0.77758091\n",
      "Iteration 114, loss = 0.77749490\n",
      "Iteration 115, loss = 0.77748969\n",
      "Iteration 116, loss = 0.77740519\n",
      "Iteration 117, loss = 0.77732202\n",
      "Iteration 118, loss = 0.77726724\n",
      "Iteration 119, loss = 0.77723553\n",
      "Iteration 120, loss = 0.77712209\n",
      "Iteration 121, loss = 0.77718276\n",
      "Iteration 122, loss = 0.77698958\n",
      "Iteration 123, loss = 0.77691670\n",
      "Iteration 124, loss = 0.77689060\n",
      "Iteration 125, loss = 0.77685187\n",
      "Iteration 126, loss = 0.77679448\n",
      "Iteration 127, loss = 0.77677901\n",
      "Iteration 128, loss = 0.77666733\n",
      "Iteration 129, loss = 0.77674429\n",
      "Iteration 130, loss = 0.77656356\n",
      "Iteration 131, loss = 0.77643814\n",
      "Iteration 132, loss = 0.77638579\n",
      "Iteration 133, loss = 0.77639983\n",
      "Iteration 134, loss = 0.77622714\n",
      "Iteration 135, loss = 0.77623685\n",
      "Iteration 136, loss = 0.77629386\n",
      "Iteration 137, loss = 0.77614753\n",
      "Iteration 138, loss = 0.77622727\n",
      "Iteration 139, loss = 0.77619860\n",
      "Iteration 140, loss = 0.77606373\n",
      "Iteration 141, loss = 0.77597465\n",
      "Iteration 142, loss = 0.77588481\n",
      "Iteration 143, loss = 0.77588742\n",
      "Iteration 144, loss = 0.77594562\n",
      "Iteration 145, loss = 0.77571790\n",
      "Iteration 146, loss = 0.77579315\n",
      "Iteration 147, loss = 0.77572954\n",
      "Iteration 148, loss = 0.77566803\n",
      "Iteration 149, loss = 0.77560769\n",
      "Iteration 150, loss = 0.77566242\n",
      "Iteration 151, loss = 0.77549672\n",
      "Iteration 152, loss = 0.77553043\n",
      "Iteration 153, loss = 0.77548321\n",
      "Iteration 154, loss = 0.77545784\n",
      "Iteration 155, loss = 0.77530614\n",
      "Iteration 156, loss = 0.77530558\n",
      "Iteration 157, loss = 0.77531708\n",
      "Iteration 158, loss = 0.77528778\n",
      "Iteration 159, loss = 0.77529120\n",
      "Iteration 160, loss = 0.77523790\n",
      "Iteration 161, loss = 0.77513008\n",
      "Iteration 162, loss = 0.77515530\n",
      "Iteration 163, loss = 0.77501596\n",
      "Iteration 164, loss = 0.77514918\n",
      "Iteration 165, loss = 0.77497382\n",
      "Iteration 166, loss = 0.77491694\n",
      "Iteration 167, loss = 0.77487554\n",
      "Iteration 168, loss = 0.77498261\n",
      "Iteration 169, loss = 0.77491705\n",
      "Iteration 170, loss = 0.77478839\n",
      "Iteration 171, loss = 0.77472771\n",
      "Iteration 172, loss = 0.77475293\n",
      "Iteration 173, loss = 0.77467190\n",
      "Iteration 174, loss = 0.77461574\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "it=3\n",
    "for i in range(it):\n",
    "  seed = np.random.randint(0,60000)\n",
    "  #divido en train y valid\n",
    "  X_train, X_valid, y_train, y_valid = train_test_split(df_concat[['text']], df_concat[['gold_label']], test_size=0.2, random_state=seed)\n",
    "  text_train = X_train[\"text\"].tolist()\n",
    "  text_valid = X_valid[\"text\"].tolist()\n",
    "  lab_train = y_train[\"gold_label\"].tolist()\n",
    "  lab_valid = y_valid[\"gold_label\"].tolist()\n",
    "  #armamos nuestro vocabulario\n",
    "  cv = CountVectorizer(min_df=100)\n",
    "  cv_train = cv.fit_transform(text_train)\n",
    "  cv_valid = cv.transform(text_valid)\n",
    "  #armamos nuestro modelo y lo entrenamos con el vocbulario de entrenamiento\n",
    "  clf = MLPClassifier(hidden_layer_sizes=(10,10,10), batch_size=1000, verbose=1)\n",
    "  clf.fit(X=cv_train, y=lab_train)\n",
    "  #guardamos los valores del score de train y test para cada iteración\n",
    "  train_score.append(clf.score(cv_train, lab_train))\n",
    "  valid_score.append(clf.score(cv_valid, lab_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wih1FRVYKwcV",
   "metadata": {
    "id": "wih1FRVYKwcV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VbygwL1Zj6bq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1633263718087,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "VbygwL1Zj6bq",
    "outputId": "9c90a899-4c0a-4142-b483-cdfbc3cdde7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores para el entrenamiento: [0.6641057565712267, 0.6610903352281237, 0.6620470441494344]\n",
      "Scores para la validación: [0.6229055274404964, 0.6247563527118614, 0.6232274100963859]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scores para el entrenamiento: {train_score}\")\n",
    "print(f\"Scores para la validación: {valid_score}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vKf1Judh5-LK",
   "metadata": {
    "id": "vKf1Judh5-LK"
   },
   "source": [
    "**Como podemos ver previamente en cada iteración la variación tanto del accuracy para el conjunto de entrenamiento como para el conjunto de validación es muy chica, por lo tanto, podemos utilizar el método de validación de Hold out, con los conjuntos establecidos inicialmente. Dichos conjuntos se separarán en sus clases y el texto a procesar, y serán convertidos a listas a continuación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bMunPWVkgqA2",
   "metadata": {
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1633386149345,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "bMunPWVkgqA2"
   },
   "outputs": [],
   "source": [
    "text_train = df_train[\"text\"].tolist()\n",
    "labels_train = df_train[\"gold_label\"].tolist() \n",
    "text_val = df_valid[\"text\"].tolist()\n",
    "labels_val = df_valid[\"gold_label\"].tolist()\n",
    "text_test = df_test[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yiXvJmuIIQaH",
   "metadata": {
    "id": "yiXvJmuIIQaH"
   },
   "source": [
    "## No hacemos preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yV_AEUIiIU9K",
   "metadata": {
    "id": "yV_AEUIiIU9K"
   },
   "source": [
    "En el modelo de Naive Bayes se analizó que los tipos de preprocesamientos del vocabulario propuestos no ayudan a mejorar el score, por lo que inicialmente no se realizará el preprocesamiento de las frases, sino que únicamente se intentará ajustar parámetros estructurales del vocabulario (n-grams, df_min, df_max) e hiperparámetros de la red (Cantidad de capas y perceptrones por capa, función de activación, learning rate, etc) para intentar mejorar el score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bzSrTfCJhsj",
   "metadata": {
    "id": "8bzSrTfCJhsj"
   },
   "source": [
    "Inicialmente se entrenará una red con 3 capas ocultas, cada una con 10 perceptrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hwj_hPzekQYF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2226482,
     "status": "ok",
     "timestamp": 1633300991168,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "hwj_hPzekQYF",
    "outputId": "616bd69a-f667-4ad1-b26e-d1aab02e4581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.83745453\n",
      "Iteration 2, loss = 0.76071949\n",
      "Iteration 3, loss = 0.73792241\n",
      "Iteration 4, loss = 0.72089942\n",
      "Iteration 5, loss = 0.70634243\n",
      "Iteration 6, loss = 0.69334119\n",
      "Iteration 7, loss = 0.68129249\n",
      "Iteration 8, loss = 0.67034378\n",
      "Iteration 9, loss = 0.66058259\n",
      "Iteration 10, loss = 0.65113474\n",
      "Iteration 11, loss = 0.64291424\n",
      "Iteration 12, loss = 0.63466885\n",
      "Iteration 13, loss = 0.62756650\n",
      "Iteration 14, loss = 0.62061550\n",
      "Iteration 15, loss = 0.61434307\n",
      "Iteration 16, loss = 0.60823784\n",
      "Iteration 17, loss = 0.60271892\n",
      "Iteration 18, loss = 0.59747325\n",
      "Iteration 19, loss = 0.59208299\n",
      "Iteration 20, loss = 0.58759134\n",
      "Iteration 21, loss = 0.58274771\n",
      "Iteration 22, loss = 0.57876875\n",
      "Iteration 23, loss = 0.57460701\n",
      "Iteration 24, loss = 0.57078950\n",
      "Iteration 25, loss = 0.56690757\n",
      "Iteration 26, loss = 0.56311766\n",
      "Iteration 27, loss = 0.56006701\n",
      "Iteration 28, loss = 0.55687200\n",
      "Iteration 29, loss = 0.55355185\n",
      "Iteration 30, loss = 0.55099054\n",
      "Iteration 31, loss = 0.54783352\n",
      "Iteration 32, loss = 0.54548294\n",
      "Iteration 33, loss = 0.54266896\n",
      "Iteration 34, loss = 0.53982261\n",
      "Iteration 35, loss = 0.53716256\n",
      "Iteration 36, loss = 0.53473728\n",
      "Iteration 37, loss = 0.53259776\n",
      "Iteration 38, loss = 0.53034074\n",
      "Iteration 39, loss = 0.52813354\n",
      "Iteration 40, loss = 0.52583223\n",
      "Iteration 41, loss = 0.52390070\n",
      "Iteration 42, loss = 0.52199296\n",
      "Iteration 43, loss = 0.52000703\n",
      "Iteration 44, loss = 0.51783265\n",
      "Iteration 45, loss = 0.51612225\n",
      "Iteration 46, loss = 0.51437599\n",
      "Iteration 47, loss = 0.51293725\n",
      "Iteration 48, loss = 0.51102822\n",
      "Iteration 49, loss = 0.50937853\n",
      "Iteration 50, loss = 0.50752857\n",
      "Iteration 51, loss = 0.50591439\n",
      "Iteration 52, loss = 0.50471614\n",
      "Iteration 53, loss = 0.50300257\n",
      "Iteration 54, loss = 0.50168214\n",
      "Iteration 55, loss = 0.50066345\n",
      "Iteration 56, loss = 0.49894385\n",
      "Iteration 57, loss = 0.49778933\n",
      "Iteration 58, loss = 0.49614721\n",
      "Iteration 59, loss = 0.49502019\n",
      "Iteration 60, loss = 0.49421362\n",
      "Iteration 61, loss = 0.49287026\n",
      "Iteration 62, loss = 0.49128858\n",
      "Iteration 63, loss = 0.49062332\n",
      "Iteration 64, loss = 0.48941668\n",
      "Iteration 65, loss = 0.48869678\n",
      "Iteration 66, loss = 0.48746574\n",
      "Iteration 67, loss = 0.48624657\n",
      "Iteration 68, loss = 0.48554871\n",
      "Iteration 69, loss = 0.48437090\n",
      "Iteration 70, loss = 0.48336939\n",
      "Iteration 71, loss = 0.48262729\n",
      "Iteration 72, loss = 0.48172580\n",
      "Iteration 73, loss = 0.48067798\n",
      "Iteration 74, loss = 0.47995549\n",
      "Iteration 75, loss = 0.47876091\n",
      "Iteration 76, loss = 0.47811738\n",
      "Iteration 77, loss = 0.47759821\n",
      "Iteration 78, loss = 0.47635377\n",
      "Iteration 79, loss = 0.47538563\n",
      "Iteration 80, loss = 0.47467580\n",
      "Iteration 81, loss = 0.47403771\n",
      "Iteration 82, loss = 0.47303037\n",
      "Iteration 83, loss = 0.47266135\n",
      "Iteration 84, loss = 0.47169662\n",
      "Iteration 85, loss = 0.47098521\n",
      "Iteration 86, loss = 0.47011853\n",
      "Iteration 87, loss = 0.46928943\n",
      "Iteration 88, loss = 0.46852789\n",
      "Iteration 89, loss = 0.46773994\n",
      "Iteration 90, loss = 0.46752440\n",
      "Iteration 91, loss = 0.46674846\n",
      "Iteration 92, loss = 0.46602347\n",
      "Iteration 93, loss = 0.46461711\n",
      "Iteration 94, loss = 0.46491595\n",
      "Iteration 95, loss = 0.46400899\n",
      "Iteration 96, loss = 0.46279865\n",
      "Iteration 97, loss = 0.46278654\n",
      "Iteration 98, loss = 0.46228682\n",
      "Iteration 99, loss = 0.46158137\n",
      "Iteration 100, loss = 0.46064043\n",
      "Iteration 101, loss = 0.46028877\n",
      "Iteration 102, loss = 0.45983215\n",
      "Iteration 103, loss = 0.45908218\n",
      "Iteration 104, loss = 0.45818846\n",
      "Iteration 105, loss = 0.45808457\n",
      "Iteration 106, loss = 0.45702710\n",
      "Iteration 107, loss = 0.45689686\n",
      "Iteration 108, loss = 0.45602558\n",
      "Iteration 109, loss = 0.45566071\n",
      "Iteration 110, loss = 0.45516734\n",
      "Iteration 111, loss = 0.45437155\n",
      "Iteration 112, loss = 0.45401405\n",
      "Iteration 113, loss = 0.45362280\n",
      "Iteration 114, loss = 0.45321724\n",
      "Iteration 115, loss = 0.45241653\n",
      "Iteration 116, loss = 0.45179393\n",
      "Iteration 117, loss = 0.45131037\n",
      "Iteration 118, loss = 0.45125594\n",
      "Iteration 119, loss = 0.45056968\n",
      "Iteration 120, loss = 0.44998960\n",
      "Iteration 121, loss = 0.44960177\n",
      "Iteration 122, loss = 0.44940872\n",
      "Iteration 123, loss = 0.44863756\n",
      "Iteration 124, loss = 0.44810848\n",
      "Iteration 125, loss = 0.44787942\n",
      "Iteration 126, loss = 0.44722901\n",
      "Iteration 127, loss = 0.44692182\n",
      "Iteration 128, loss = 0.44617804\n",
      "Iteration 129, loss = 0.44621634\n",
      "Iteration 130, loss = 0.44537989\n",
      "Iteration 131, loss = 0.44475026\n",
      "Iteration 132, loss = 0.44487474\n",
      "Iteration 133, loss = 0.44434707\n",
      "Iteration 134, loss = 0.44361857\n",
      "Iteration 135, loss = 0.44341455\n",
      "Iteration 136, loss = 0.44360737\n",
      "Iteration 137, loss = 0.44234246\n",
      "Iteration 138, loss = 0.44193959\n",
      "Iteration 139, loss = 0.44206008\n",
      "Iteration 140, loss = 0.44102256\n",
      "Iteration 141, loss = 0.44109376\n",
      "Iteration 142, loss = 0.44083984\n",
      "Iteration 143, loss = 0.44049004\n",
      "Iteration 144, loss = 0.43938843\n",
      "Iteration 145, loss = 0.43971700\n",
      "Iteration 146, loss = 0.43917914\n",
      "Iteration 147, loss = 0.43867267\n",
      "Iteration 148, loss = 0.43855892\n",
      "Iteration 149, loss = 0.43777684\n",
      "Iteration 150, loss = 0.43763198\n",
      "Iteration 151, loss = 0.43760709\n",
      "Iteration 152, loss = 0.43672260\n",
      "Iteration 153, loss = 0.43724145\n",
      "Iteration 154, loss = 0.43652709\n",
      "Iteration 155, loss = 0.43615357\n",
      "Iteration 156, loss = 0.43596203\n",
      "Iteration 157, loss = 0.43533808\n",
      "Iteration 158, loss = 0.43512417\n",
      "Iteration 159, loss = 0.43472673\n",
      "Iteration 160, loss = 0.43426479\n",
      "Iteration 161, loss = 0.43413327\n",
      "Iteration 162, loss = 0.43365105\n",
      "Iteration 163, loss = 0.43349635\n",
      "Iteration 164, loss = 0.43313663\n",
      "Iteration 165, loss = 0.43287889\n",
      "Iteration 166, loss = 0.43296427\n",
      "Iteration 167, loss = 0.43258826\n",
      "Iteration 168, loss = 0.43203043\n",
      "Iteration 169, loss = 0.43164826\n",
      "Iteration 170, loss = 0.43131542\n",
      "Iteration 171, loss = 0.43072218\n",
      "Iteration 172, loss = 0.43099575\n",
      "Iteration 173, loss = 0.43042364\n",
      "Iteration 174, loss = 0.43010624\n",
      "Iteration 175, loss = 0.42979961\n",
      "Iteration 176, loss = 0.42965846\n",
      "Iteration 177, loss = 0.42910743\n",
      "Iteration 178, loss = 0.42904131\n",
      "Iteration 179, loss = 0.42895203\n",
      "Iteration 180, loss = 0.42859222\n",
      "Iteration 181, loss = 0.42824111\n",
      "Iteration 182, loss = 0.42833432\n",
      "Iteration 183, loss = 0.42768729\n",
      "Iteration 184, loss = 0.42792962\n",
      "Iteration 185, loss = 0.42752254\n",
      "Iteration 186, loss = 0.42717302\n",
      "Iteration 187, loss = 0.42641704\n",
      "Iteration 188, loss = 0.42641543\n",
      "Iteration 189, loss = 0.42653350\n",
      "Iteration 190, loss = 0.42574384\n",
      "Iteration 191, loss = 0.42620639\n",
      "Iteration 192, loss = 0.42509848\n",
      "Iteration 193, loss = 0.42508536\n",
      "Iteration 194, loss = 0.42496427\n",
      "Iteration 195, loss = 0.42506699\n",
      "Iteration 196, loss = 0.42466114\n",
      "Iteration 197, loss = 0.42411785\n",
      "Iteration 198, loss = 0.42378937\n",
      "Iteration 199, loss = 0.42410550\n",
      "Iteration 200, loss = 0.42331722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_train = df_train[\"text\"].tolist()\n",
    "labels_train = df_train[\"gold_label\"].tolist() \n",
    "text_val = df_valid[\"text\"].tolist()\n",
    "labels_val = df_valid[\"gold_label\"].tolist()\n",
    "text_test = df_test[\"text\"].tolist()\n",
    "#armamos nuestro vocabulario\n",
    "cv = CountVectorizer(min_df=20, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "#armamos nuestro modelo y lo entrenamos con el vocbulario de entrenamiento\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),alpha=1e-10, batch_size=300, verbose=1)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aRhRVxkoK2Cl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1270,
     "status": "ok",
     "timestamp": 1633301897576,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "aRhRVxkoK2Cl",
    "outputId": "0b4da40f-77c1-42db-d604-22118357dc52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8418234076673698\n",
      "0.61003861003861\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C-9e9L5GY9H0",
   "metadata": {
    "id": "C-9e9L5GY9H0"
   },
   "source": [
    "Se vé que llega a overfittear así que disminuímos la cantidad de iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "p4THrd6nKern",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1449614,
     "status": "ok",
     "timestamp": 1633303622262,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "p4THrd6nKern",
    "outputId": "788a2e96-d6c0-4004-d098-43b3c3c6d4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.83774259\n",
      "Iteration 2, loss = 0.76402875\n",
      "Iteration 3, loss = 0.74344423\n",
      "Iteration 4, loss = 0.72736909\n",
      "Iteration 5, loss = 0.71365951\n",
      "Iteration 6, loss = 0.70050825\n",
      "Iteration 7, loss = 0.68802369\n",
      "Iteration 8, loss = 0.67656187\n",
      "Iteration 9, loss = 0.66546039\n",
      "Iteration 10, loss = 0.65520799\n",
      "Iteration 11, loss = 0.64554202\n",
      "Iteration 12, loss = 0.63654507\n",
      "Iteration 13, loss = 0.62837128\n",
      "Iteration 14, loss = 0.62025354\n",
      "Iteration 15, loss = 0.61327836\n",
      "Iteration 16, loss = 0.60645760\n",
      "Iteration 17, loss = 0.60019750\n",
      "Iteration 18, loss = 0.59441081\n",
      "Iteration 19, loss = 0.58877511\n",
      "Iteration 20, loss = 0.58332434\n",
      "Iteration 21, loss = 0.57833657\n",
      "Iteration 22, loss = 0.57379980\n",
      "Iteration 23, loss = 0.56961963\n",
      "Iteration 24, loss = 0.56502125\n",
      "Iteration 25, loss = 0.56116818\n",
      "Iteration 26, loss = 0.55755554\n",
      "Iteration 27, loss = 0.55354097\n",
      "Iteration 28, loss = 0.55028321\n",
      "Iteration 29, loss = 0.54702838\n",
      "Iteration 30, loss = 0.54373443\n",
      "Iteration 31, loss = 0.54055280\n",
      "Iteration 32, loss = 0.53771053\n",
      "Iteration 33, loss = 0.53516302\n",
      "Iteration 34, loss = 0.53266863\n",
      "Iteration 35, loss = 0.52967011\n",
      "Iteration 36, loss = 0.52747063\n",
      "Iteration 37, loss = 0.52499613\n",
      "Iteration 38, loss = 0.52274881\n",
      "Iteration 39, loss = 0.52033787\n",
      "Iteration 40, loss = 0.51824661\n",
      "Iteration 41, loss = 0.51620137\n",
      "Iteration 42, loss = 0.51409469\n",
      "Iteration 43, loss = 0.51227789\n",
      "Iteration 44, loss = 0.51036340\n",
      "Iteration 45, loss = 0.50872839\n",
      "Iteration 46, loss = 0.50671591\n",
      "Iteration 47, loss = 0.50504156\n",
      "Iteration 48, loss = 0.50328253\n",
      "Iteration 49, loss = 0.50207880\n",
      "Iteration 50, loss = 0.50041381\n",
      "Iteration 51, loss = 0.49862858\n",
      "Iteration 52, loss = 0.49747121\n",
      "Iteration 53, loss = 0.49551996\n",
      "Iteration 54, loss = 0.49449108\n",
      "Iteration 55, loss = 0.49306792\n",
      "Iteration 56, loss = 0.49172807\n",
      "Iteration 57, loss = 0.49046044\n",
      "Iteration 58, loss = 0.48908018\n",
      "Iteration 59, loss = 0.48795708\n",
      "Iteration 60, loss = 0.48683457\n",
      "Iteration 61, loss = 0.48491863\n",
      "Iteration 62, loss = 0.48462337\n",
      "Iteration 63, loss = 0.48334096\n",
      "Iteration 64, loss = 0.48191250\n",
      "Iteration 65, loss = 0.48084815\n",
      "Iteration 66, loss = 0.47970640\n",
      "Iteration 67, loss = 0.47920946\n",
      "Iteration 68, loss = 0.47778831\n",
      "Iteration 69, loss = 0.47704562\n",
      "Iteration 70, loss = 0.47603024\n",
      "Iteration 71, loss = 0.47447291\n",
      "Iteration 72, loss = 0.47399541\n",
      "Iteration 73, loss = 0.47328411\n",
      "Iteration 74, loss = 0.47194421\n",
      "Iteration 75, loss = 0.47126617\n",
      "Iteration 76, loss = 0.47028730\n",
      "Iteration 77, loss = 0.46941037\n",
      "Iteration 78, loss = 0.46898345\n",
      "Iteration 79, loss = 0.46774405\n",
      "Iteration 80, loss = 0.46689440\n",
      "Iteration 81, loss = 0.46611793\n",
      "Iteration 82, loss = 0.46541607\n",
      "Iteration 83, loss = 0.46501204\n",
      "Iteration 84, loss = 0.46348521\n",
      "Iteration 85, loss = 0.46309605\n",
      "Iteration 86, loss = 0.46242229\n",
      "Iteration 87, loss = 0.46168009\n",
      "Iteration 88, loss = 0.46108465\n",
      "Iteration 89, loss = 0.46016240\n",
      "Iteration 90, loss = 0.45986713\n",
      "Iteration 91, loss = 0.45884053\n",
      "Iteration 92, loss = 0.45831017\n",
      "Iteration 93, loss = 0.45773874\n",
      "Iteration 94, loss = 0.45715146\n",
      "Iteration 95, loss = 0.45669539\n",
      "Iteration 96, loss = 0.45580963\n",
      "Iteration 97, loss = 0.45544284\n",
      "Iteration 98, loss = 0.45476746\n",
      "Iteration 99, loss = 0.45425545\n",
      "Iteration 100, loss = 0.45339912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=20, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "#armamos nuestro modelo y lo entrenamos con el vocbulario de entrenamiento\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=100,alpha=1e-10, batch_size=300, verbose=1)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "I8BgqPh-SlTO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1633303625612,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "I8BgqPh-SlTO",
    "outputId": "02777411-d118-4a40-bbf2-b8b14a2cac94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8246709394630547\n",
      "0.6160333265596424\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z53ldXyf2Gm8",
   "metadata": {
    "id": "z53ldXyf2Gm8"
   },
   "source": [
    "Como sigue Overfitteando le aplicamos Early Stopping par que si el Score del Test comienza a bajar, el modelo deje de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "OjpIoNqjceL1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206124,
     "status": "ok",
     "timestamp": 1633304265265,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "OjpIoNqjceL1",
    "outputId": "ba215bb2-8ce0-46e8-ed58-98f9dc8b2f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.85304142\n",
      "Validation score: 0.650236\n",
      "Iteration 2, loss = 0.76413698\n",
      "Validation score: 0.655606\n",
      "Iteration 3, loss = 0.74212184\n",
      "Validation score: 0.656115\n",
      "Iteration 4, loss = 0.72590926\n",
      "Validation score: 0.653494\n",
      "Iteration 5, loss = 0.71128290\n",
      "Validation score: 0.653130\n",
      "Iteration 6, loss = 0.69803032\n",
      "Validation score: 0.651146\n",
      "Iteration 7, loss = 0.68556013\n",
      "Validation score: 0.647469\n",
      "Iteration 8, loss = 0.67396075\n",
      "Validation score: 0.645831\n",
      "Iteration 9, loss = 0.66297524\n",
      "Validation score: 0.645903\n",
      "Iteration 10, loss = 0.65293088\n",
      "Validation score: 0.640971\n",
      "Iteration 11, loss = 0.64337274\n",
      "Validation score: 0.638932\n",
      "Iteration 12, loss = 0.63424400\n",
      "Validation score: 0.639205\n",
      "Iteration 13, loss = 0.62600839\n",
      "Validation score: 0.637567\n",
      "Iteration 14, loss = 0.61805013\n",
      "Validation score: 0.635564\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=20, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "#armamos nuestro modelo y lo entrenamos con el vocbulario de entrenamiento\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True )\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "qZzgYmZSe8Yb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1490,
     "status": "ok",
     "timestamp": 1633304016394,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "qZzgYmZSe8Yb",
    "outputId": "528f451c-dbc2-4ea1-9272-fb02bbb23fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695418545344005\n",
      "0.6595204226783175\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gvPMSibp2wOU",
   "metadata": {
    "id": "gvPMSibp2wOU"
   },
   "source": [
    "Podemos ver que con n-grams=(1,2) y aplicando Early Stopping mejora el Validation Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UfNU538G3V9s",
   "metadata": {
    "id": "UfNU538G3V9s"
   },
   "source": [
    "No se intentará entrenar el modelo con n-grams=(1,2,3), ya que esto tardará demaasiado en correr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HvJcy2xTCZ0f",
   "metadata": {
    "id": "HvJcy2xTCZ0f"
   },
   "source": [
    "### Variando min_df y max_df:\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "EyPZ6R-L3g3r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285230,
     "status": "ok",
     "timestamp": 1633310722127,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "EyPZ6R-L3g3r",
    "outputId": "10a7aaf1-2c45-4a8d-f7cd-ba122a3a626e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.86557343\n",
      "Validation score: 0.654677\n",
      "Iteration 2, loss = 0.74731671\n",
      "Validation score: 0.656752\n",
      "Iteration 3, loss = 0.71301106\n",
      "Validation score: 0.656497\n",
      "Iteration 4, loss = 0.68625771\n",
      "Validation score: 0.656115\n",
      "Iteration 5, loss = 0.66225375\n",
      "Validation score: 0.652821\n",
      "Iteration 6, loss = 0.63998812\n",
      "Validation score: 0.648579\n",
      "Iteration 7, loss = 0.61886940\n",
      "Validation score: 0.647742\n",
      "Iteration 8, loss = 0.59882145\n",
      "Validation score: 0.643847\n",
      "Iteration 9, loss = 0.58003091\n",
      "Validation score: 0.641608\n",
      "Iteration 10, loss = 0.56243522\n",
      "Validation score: 0.636729\n",
      "Iteration 11, loss = 0.54648067\n",
      "Validation score: 0.633016\n",
      "Iteration 12, loss = 0.53164802\n",
      "Validation score: 0.630559\n",
      "Iteration 13, loss = 0.51805761\n",
      "Validation score: 0.630286\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=10, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "j46qT9RA591O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1186,
     "status": "ok",
     "timestamp": 1633310742771,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "j46qT9RA591O",
    "outputId": "fa54f3e0-c2bd-46e7-ede0-b837990fd36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7007974632622637\n",
      "0.6635846372688478\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pUBeER736ILB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476803,
     "status": "ok",
     "timestamp": 1633318922638,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "pUBeER736ILB",
    "outputId": "78696cdc-208e-4ac1-8d20-c345aa3436c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.83422967\n",
      "Validation score: 0.654149\n",
      "Iteration 2, loss = 0.72442467\n",
      "Validation score: 0.656825\n",
      "Iteration 3, loss = 0.67617434\n",
      "Validation score: 0.654331\n",
      "Iteration 4, loss = 0.63888778\n",
      "Validation score: 0.650181\n",
      "Iteration 5, loss = 0.60612770\n",
      "Validation score: 0.646777\n",
      "Iteration 6, loss = 0.57526727\n",
      "Validation score: 0.642663\n",
      "Iteration 7, loss = 0.54586846\n",
      "Validation score: 0.639241\n",
      "Iteration 8, loss = 0.51905961\n",
      "Validation score: 0.635401\n",
      "Iteration 9, loss = 0.49315406\n",
      "Validation score: 0.630832\n",
      "Iteration 10, loss = 0.47039289\n",
      "Validation score: 0.630577\n",
      "Iteration 11, loss = 0.44895231\n",
      "Validation score: 0.626882\n",
      "Iteration 12, loss = 0.43064936\n",
      "Validation score: 0.627155\n",
      "Iteration 13, loss = 0.41418631\n",
      "Validation score: 0.623241\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=5, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "tdlFe4EU8DO2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1633318939989,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "tdlFe4EU8DO2",
    "outputId": "c20aae1e-a2ae-4259-bfe7-1fcc2b8d3228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722784586624242\n",
      "0.6607396870554765\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kyJsGVYcSEdv",
   "metadata": {
    "id": "kyJsGVYcSEdv"
   },
   "outputs": [],
   "source": [
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Z-u40-hz8ITk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2102297,
     "status": "ok",
     "timestamp": 1633313415827,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "Z-u40-hz8ITk",
    "outputId": "d9135978-02db-4333-c7c5-be697ae48b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.83443676\n",
      "Validation score: 0.657499\n",
      "Iteration 2, loss = 0.64670872\n",
      "Validation score: 0.650181\n",
      "Iteration 3, loss = 0.52068919\n",
      "Validation score: 0.640188\n",
      "Iteration 4, loss = 0.44094559\n",
      "Validation score: 0.631997\n",
      "Iteration 5, loss = 0.39087037\n",
      "Validation score: 0.624716\n",
      "Iteration 6, loss = 0.35759449\n",
      "Validation score: 0.622185\n",
      "Iteration 7, loss = 0.33302283\n",
      "Validation score: 0.620638\n",
      "Iteration 8, loss = 0.31442518\n",
      "Validation score: 0.617689\n",
      "Iteration 9, loss = 0.29805723\n",
      "Validation score: 0.614759\n",
      "Iteration 10, loss = 0.28585299\n",
      "Validation score: 0.616907\n",
      "Iteration 11, loss = 0.27482704\n",
      "Validation score: 0.611573\n",
      "Iteration 12, loss = 0.26641224\n",
      "Validation score: 0.611901\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=1, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6L6BB2lLE1f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1633313592778,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "6L6BB2lLE1f4",
    "outputId": "d43d99ce-be67-41ce-a9d1-45321606486e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343742889543784\n",
      "0.6730339361918309\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04NAzF1DlXRj",
   "metadata": {
    "id": "04NAzF1DlXRj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85riswToOQnx",
   "metadata": {
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1633316283504,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "85riswToOQnx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "SRXFynzHE9YE",
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1633316744908,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "SRXFynzHE9YE"
   },
   "outputs": [],
   "source": [
    "X_test = cv.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "iszE_6OsREZd",
   "metadata": {
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1633316793959,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "iszE_6OsREZd"
   },
   "outputs": [],
   "source": [
    "test_class = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "j_P-5-AlRHeL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1633316809329,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "j_P-5-AlRHeL",
    "outputId": "85f3901a-9240-409d-8e79-f61247ae2197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9824,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1iVaPX3yRUyD",
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1633316855706,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "1iVaPX3yRUyD"
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(data=test_class, columns=['pred_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "QC7GaeaeRWoD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1633316870770,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "QC7GaeaeRWoD",
    "outputId": "ff0d1592-97b0-4fb6-8e4a-79ccab454ef8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819</th>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821</th>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9822</th>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9824 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred_labels\n",
       "pairID               \n",
       "0       contradiction\n",
       "1             neutral\n",
       "2       contradiction\n",
       "3          entailment\n",
       "4             neutral\n",
       "...               ...\n",
       "9819    contradiction\n",
       "9820       entailment\n",
       "9821    contradiction\n",
       "9822       entailment\n",
       "9823          neutral\n",
       "\n",
       "[9824 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.index.names = ['pairID']\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "GkE3g-2kRnks",
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1633316944177,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "GkE3g-2kRnks"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/MyDrive/Redes TPS/TP Redes 1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "FshVIvETRd5Z",
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1633316946730,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "FshVIvETRd5Z"
   },
   "outputs": [],
   "source": [
    "submit.to_csv(path+'submission_mlp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_xk_MizCXqS7",
   "metadata": {
    "id": "_xk_MizCXqS7"
   },
   "source": [
    "## Modificando hiperparámetros de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mFT969A9Xx4O",
   "metadata": {
    "id": "mFT969A9Xx4O"
   },
   "source": [
    "Para esto utilizaremos la herramienta GridSearchCV de scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "TzaT26E8YIHN",
   "metadata": {
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1633341850769,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "TzaT26E8YIHN"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "LOb3r_nhbZCO",
   "metadata": {
    "executionInfo": {
     "elapsed": 4044,
     "status": "ok",
     "timestamp": 1633386320475,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "LOb3r_nhbZCO"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=1, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "BrliXdynbhtR",
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1633355206712,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "BrliXdynbhtR"
   },
   "outputs": [],
   "source": [
    "#mlp_gs = MLPClassifier(max_iter=50, early_stopping=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "GgZrUNI6bZks",
   "metadata": {
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1633355208144,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "GgZrUNI6bZks"
   },
   "outputs": [],
   "source": [
    "#parameter_space = {\n",
    "    #'hidden_layer_sizes': [(30,),(20,10),(10,20),(10,10,10)],\n",
    "    #'activation': ['tanh', 'relu'],\n",
    "    #'solver': ['sgd', 'adam'],\n",
    "    #'alpha': [1e-10],\n",
    "    #'learning_rate': ['constant','adaptive'],\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5Rsgf2Yec1t-",
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1633398997531,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "5Rsgf2Yec1t-"
   },
   "outputs": [],
   "source": [
    "#clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=3)\n",
    "#clf.fit(cv_train, labels_train) # X is train samples and y is the corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lD64RBdJ4NKJ",
   "metadata": {
    "id": "lD64RBdJ4NKJ"
   },
   "source": [
    "Como cada modelo lleva aprox 40 minutos de entrenamiento, al intentar utilizar la herramienta propuesta, por la cantidad de combinaciones posibles, esto lleva demasiado tiempo y termina rompiendo antes de terminar de correr, por lo que se optó por variar cada hiperparámetro individualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h38F9SJL4yMX",
   "metadata": {
    "id": "h38F9SJL4yMX"
   },
   "source": [
    "### Variando la cantidad y tamaño de las capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "IwdFu1bhSvge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1259335,
     "status": "ok",
     "timestamp": 1633361549967,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "IwdFu1bhSvge",
    "outputId": "b96a5c7b-210c-4e91-e7fd-f832f5ef19ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.82609114\n",
      "Validation score: 0.654368\n",
      "Iteration 2, loss = 0.63861877\n",
      "Validation score: 0.647487\n",
      "Iteration 3, loss = 0.51046482\n",
      "Validation score: 0.637385\n",
      "Iteration 4, loss = 0.42233998\n",
      "Validation score: 0.631196\n",
      "Iteration 5, loss = 0.36152831\n",
      "Validation score: 0.627901\n",
      "Iteration 6, loss = 0.31710388\n",
      "Validation score: 0.623441\n",
      "Iteration 7, loss = 0.28305904\n",
      "Validation score: 0.617744\n",
      "Iteration 8, loss = 0.25655691\n",
      "Validation score: 0.614631\n",
      "Iteration 9, loss = 0.23599356\n",
      "Validation score: 0.612429\n",
      "Iteration 10, loss = 0.21916215\n",
      "Validation score: 0.609116\n",
      "Iteration 11, loss = 0.20606148\n",
      "Validation score: 0.607732\n",
      "Iteration 12, loss = 0.19508089\n",
      "Validation score: 0.605148\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=1, ngram_range = (1,2)) \n",
    "cv_train = cv.fit_transform(text_train)\n",
    "cv_valid = cv.transform(text_val)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30,),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "I77IxMsFlZ0V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1645,
     "status": "ok",
     "timestamp": 1633362363475,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "I77IxMsFlZ0V",
    "outputId": "df2d0243-ec06-4721-a78a-cadd28678b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7390960869509817\n",
      "0.6665311928469824\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mdhE9dnskzmO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3618041,
     "status": "ok",
     "timestamp": 1633365998110,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "mdhE9dnskzmO",
    "outputId": "396f3a99-4142-40c3-fc2d-5c7256797c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.82404596\n",
      "Validation score: 0.659574\n",
      "Iteration 2, loss = 0.63701845\n",
      "Validation score: 0.649617\n",
      "Iteration 3, loss = 0.50616471\n",
      "Validation score: 0.639587\n",
      "Iteration 4, loss = 0.41769893\n",
      "Validation score: 0.632707\n",
      "Iteration 5, loss = 0.35879993\n",
      "Validation score: 0.624716\n",
      "Iteration 6, loss = 0.31843776\n",
      "Validation score: 0.621020\n",
      "Iteration 7, loss = 0.28756015\n",
      "Validation score: 0.617052\n",
      "Iteration 8, loss = 0.26478998\n",
      "Validation score: 0.618308\n",
      "Iteration 9, loss = 0.24715206\n",
      "Validation score: 0.616324\n",
      "Iteration 10, loss = 0.23230432\n",
      "Validation score: 0.614832\n",
      "Iteration 11, loss = 0.22043976\n",
      "Validation score: 0.610536\n",
      "Iteration 12, loss = 0.21038829\n",
      "Validation score: 0.612010\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(20,10),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "BL6FUgfHlix1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1643,
     "status": "ok",
     "timestamp": 1633370089620,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "BL6FUgfHlix1",
    "outputId": "5985d5be-f9b7-46a5-d221-c197b1ac8698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407052116344811\n",
      "0.6692745376955903\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5DHpxcfkF1Rt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1966003,
     "status": "ok",
     "timestamp": 1633372064845,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "5DHpxcfkF1Rt",
    "outputId": "0e7d3835-da42-4732-f394-2ec31b911934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.82675551\n",
      "Validation score: 0.656971\n",
      "Iteration 2, loss = 0.64979012\n",
      "Validation score: 0.650673\n",
      "Iteration 3, loss = 0.53012811\n",
      "Validation score: 0.637694\n",
      "Iteration 4, loss = 0.45266899\n",
      "Validation score: 0.632069\n",
      "Iteration 5, loss = 0.40213258\n",
      "Validation score: 0.625972\n",
      "Iteration 6, loss = 0.36654475\n",
      "Validation score: 0.623496\n",
      "Iteration 7, loss = 0.33908577\n",
      "Validation score: 0.620292\n",
      "Iteration 8, loss = 0.31872493\n",
      "Validation score: 0.618763\n",
      "Iteration 9, loss = 0.30186487\n",
      "Validation score: 0.615123\n",
      "Iteration 10, loss = 0.28798130\n",
      "Validation score: 0.614722\n",
      "Iteration 11, loss = 0.27640811\n",
      "Validation score: 0.613430\n",
      "Iteration 12, loss = 0.26598066\n",
      "Validation score: 0.610973\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes=(10,20),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf2.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pz-gF81jF5zg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1272,
     "status": "ok",
     "timestamp": 1633372193329,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "pz-gF81jF5zg",
    "outputId": "352430ab-6efa-47d9-8d20-70e1506185b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7348857867327305\n",
      "0.6733387522861207\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rZhnJWT5luNH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2828198,
     "status": "ok",
     "timestamp": 1633375865668,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "rZhnJWT5luNH",
    "outputId": "a2766911-54c2-4f5c-84cb-2382f5bba75e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.82490961\n",
      "Validation score: 0.653348\n",
      "Iteration 2, loss = 0.63661065\n",
      "Validation score: 0.645776\n",
      "Iteration 3, loss = 0.50634289\n",
      "Validation score: 0.634436\n",
      "Iteration 4, loss = 0.42039746\n",
      "Validation score: 0.630067\n",
      "Iteration 5, loss = 0.36458018\n",
      "Validation score: 0.624097\n",
      "Iteration 6, loss = 0.32609128\n",
      "Validation score: 0.622713\n",
      "Iteration 7, loss = 0.29830175\n",
      "Validation score: 0.618618\n",
      "Iteration 8, loss = 0.27668583\n",
      "Validation score: 0.617289\n",
      "Iteration 9, loss = 0.25928622\n",
      "Validation score: 0.613375\n",
      "Iteration 10, loss = 0.24645186\n",
      "Validation score: 0.610609\n",
      "Iteration 11, loss = 0.23472093\n",
      "Validation score: 0.609225\n",
      "Iteration 12, loss = 0.22561303\n",
      "Validation score: 0.609389\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(15, 15, 15), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes=(15,15,15),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf2.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Nc5vknS8tcwy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1709,
     "status": "ok",
     "timestamp": 1633375880931,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "Nc5vknS8tcwy",
    "outputId": "785b48ab-0ad8-4bd5-f721-2455b9fd1af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7379001650991049\n",
      "0.6692745376955903\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lgCNjDU9ynDP",
   "metadata": {
    "id": "lgCNjDU9ynDP"
   },
   "source": [
    "### Variando alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "C8F0FzT2ykfS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1969398,
     "status": "ok",
     "timestamp": 1633377923361,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "C8F0FzT2ykfS",
    "outputId": "c896e9cc-f3f4-46aa-a773-1fb0dd5084a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.84999704\n",
      "Validation score: 0.652566\n",
      "Iteration 2, loss = 0.66128546\n",
      "Validation score: 0.645412\n",
      "Iteration 3, loss = 0.54129175\n",
      "Validation score: 0.637057\n",
      "Iteration 4, loss = 0.46288523\n",
      "Validation score: 0.631833\n",
      "Iteration 5, loss = 0.41174070\n",
      "Validation score: 0.628156\n",
      "Iteration 6, loss = 0.37609442\n",
      "Validation score: 0.623933\n",
      "Iteration 7, loss = 0.34976607\n",
      "Validation score: 0.619801\n",
      "Iteration 8, loss = 0.32831947\n",
      "Validation score: 0.616688\n",
      "Iteration 9, loss = 0.31161324\n",
      "Validation score: 0.614067\n",
      "Iteration 10, loss = 0.29705900\n",
      "Validation score: 0.611045\n",
      "Iteration 11, loss = 0.28553917\n",
      "Validation score: 0.611282\n",
      "Iteration 12, loss = 0.27484671\n",
      "Validation score: 0.610117\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-09, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-9, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf2.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7rGa1xt48uEy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1667,
     "status": "ok",
     "timestamp": 1633378583903,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "7rGa1xt48uEy",
    "outputId": "d5737d35-591a-4c46-c33b-06f37a6e38b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7289480438395463\n",
      "0.6716114610851452\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "y5gDELJ-FiKw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2363976,
     "status": "ok",
     "timestamp": 1633388693046,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "y5gDELJ-FiKw",
    "outputId": "0cbdb3ce-05a9-4844-fc23-2454fabfbff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.84594094\n",
      "Validation score: 0.654623\n",
      "Iteration 2, loss = 0.66163852\n",
      "Validation score: 0.651437\n",
      "Iteration 3, loss = 0.54177691\n",
      "Validation score: 0.638804\n",
      "Iteration 4, loss = 0.46017614\n",
      "Validation score: 0.633107\n",
      "Iteration 5, loss = 0.40770787\n",
      "Validation score: 0.628738\n",
      "Iteration 6, loss = 0.37150017\n",
      "Validation score: 0.625535\n",
      "Iteration 7, loss = 0.34469974\n",
      "Validation score: 0.623951\n",
      "Iteration 8, loss = 0.32455318\n",
      "Validation score: 0.622477\n",
      "Iteration 9, loss = 0.30784780\n",
      "Validation score: 0.621912\n",
      "Iteration 10, loss = 0.29393413\n",
      "Validation score: 0.619018\n",
      "Iteration 11, loss = 0.28231242\n",
      "Validation score: 0.617143\n",
      "Iteration 12, loss = 0.27265504\n",
      "Validation score: 0.615250\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-08, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-8, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf2.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ChPqmu2SZCmu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 833,
     "status": "ok",
     "timestamp": 1633388694455,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "ChPqmu2SZCmu",
    "outputId": "b2ca77a5-7649-4a8e-f2cb-a68fea0555c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7269912462889107\n",
      "0.6691729323308271\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3QA02p9ckFlv",
   "metadata": {
    "id": "3QA02p9ckFlv"
   },
   "outputs": [],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x6Lnw9cha-Rf",
   "metadata": {
    "id": "x6Lnw9cha-Rf"
   },
   "source": [
    "## Variando learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6OBYWbccbCn1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2751348,
     "status": "ok",
     "timestamp": 1633391727758,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "6OBYWbccbCn1",
    "outputId": "9f92d56e-17ac-420c-e1d8-dc8511820864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.00745029\n",
      "Validation score: 0.623751\n",
      "Iteration 2, loss = 0.80128339\n",
      "Validation score: 0.649307\n",
      "Iteration 3, loss = 0.71255460\n",
      "Validation score: 0.653112\n",
      "Iteration 4, loss = 0.64840109\n",
      "Validation score: 0.652584\n",
      "Iteration 5, loss = 0.59291322\n",
      "Validation score: 0.649453\n",
      "Iteration 6, loss = 0.54544695\n",
      "Validation score: 0.643628\n",
      "Iteration 7, loss = 0.50591727\n",
      "Validation score: 0.638768\n",
      "Iteration 8, loss = 0.47414756\n",
      "Validation score: 0.635291\n",
      "Iteration 9, loss = 0.44878951\n",
      "Validation score: 0.631305\n",
      "Iteration 10, loss = 0.42858899\n",
      "Validation score: 0.626172\n",
      "Iteration 11, loss = 0.41245267\n",
      "Validation score: 0.623842\n",
      "Iteration 12, loss = 0.39914344\n",
      "Validation score: 0.622986\n",
      "Iteration 13, loss = 0.38842810\n",
      "Validation score: 0.619127\n",
      "Iteration 14, loss = 0.37939947\n",
      "Validation score: 0.617416\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.0001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10,10,10),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True, learning_rate_init=0.0001)\n",
    "clf.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KMBdAy4Ba72n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1633392180161,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "KMBdAy4Ba72n",
    "outputId": "db74958c-3684-481e-d29c-1e363d23315d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7299273527532597\n",
      "0.6705954074375127\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(cv_train, labels_train))\n",
    "print(clf.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Oyg_JGAEboqV",
   "metadata": {
    "id": "Oyg_JGAEboqV"
   },
   "source": [
    "# Validación y métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fIMTqT5WbjAY",
   "metadata": {
    "id": "fIMTqT5WbjAY"
   },
   "source": [
    "Tomaremos el modelo cuyo Accuracy en el set de validación resultó más alto. Éste modelo tiene la siguiente estructura:\n",
    "\n",
    "Es un modelo de Multiple layer Perceptron con dos capas ocultas, una de ellas conformada por 10 perceptrones y otra por 20. La función de activación de los perceptrones es ReLu, y al ser un modelo de clasificación tiene una capa de activación SoftMax en su salida. \n",
    "\n",
    "Estas capas se mostrarán en la siguiente celda:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W38qp78KdgWd",
   "metadata": {
    "id": "W38qp78KdgWd"
   },
   "source": [
    "Además, el modelo es entrenado con los siguientes hiperparámetros: \n",
    "\n",
    "* Una cantidad máxima de 50 iteraciones con Early Stopping activado\n",
    "* Un optimizador ADAM \n",
    "* Función de pérdida a optimizar: log-loss function, alpha= 1e-10\n",
    "* Learning rate de 0,001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G9DGcNFifwhf",
   "metadata": {
    "id": "G9DGcNFifwhf"
   },
   "source": [
    "Como lenguaje se tomarán n-grams conformados por una y por dos palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "D3LixdQ1df-E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2432202,
     "status": "ok",
     "timestamp": 1633397269625,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "D3LixdQ1df-E",
    "outputId": "854df4a8-f60a-4f66-ec5a-c510f3e730d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.82960469\n",
      "Validation score: 0.656643\n",
      "Iteration 2, loss = 0.64544693\n",
      "Validation score: 0.650218\n",
      "Iteration 3, loss = 0.51942967\n",
      "Validation score: 0.638750\n",
      "Iteration 4, loss = 0.43791598\n",
      "Validation score: 0.631560\n",
      "Iteration 5, loss = 0.38678032\n",
      "Validation score: 0.630031\n",
      "Iteration 6, loss = 0.35120671\n",
      "Validation score: 0.623532\n",
      "Iteration 7, loss = 0.32565013\n",
      "Validation score: 0.621912\n",
      "Iteration 8, loss = 0.30581048\n",
      "Validation score: 0.618909\n",
      "Iteration 9, loss = 0.29076624\n",
      "Validation score: 0.614413\n",
      "Iteration 10, loss = 0.27830315\n",
      "Validation score: 0.612611\n",
      "Iteration 11, loss = 0.26734220\n",
      "Validation score: 0.611391\n",
      "Iteration 12, loss = 0.25841205\n",
      "Validation score: 0.611318\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-10, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes=(10,20),max_iter=50,alpha=1e-10, batch_size=300, verbose=1, early_stopping=True)\n",
    "clf2.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "p6VW67nBxMf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1340,
     "status": "ok",
     "timestamp": 1633397295022,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "p6VW67nBxMf2",
    "outputId": "1abc2edf-6dce-4dbc-b796-d8ab19eb4ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7348584825808613\n",
      "0.6676488518593782\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(cv_train, labels_train))\n",
    "print(clf2.score(cv_valid, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lvubmHQ0gCIf",
   "metadata": {
    "id": "lvubmHQ0gCIf"
   },
   "source": [
    "Como método de validación se utiliza el método de Hold Out validation, utilizando la partición ya dada para Train y Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "--sKl6XkpUQQ",
   "metadata": {
    "id": "--sKl6XkpUQQ"
   },
   "source": [
    "Para calcular las métricas y evaluar el desempeño del modelo utilizaremos el Validation_set. En primer lugar calculamos y graficamos la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "q_aDO4fbxISh",
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1633397613648,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "q_aDO4fbxISh"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0qqjWr1L6mvR",
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1633397576341,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "0qqjWr1L6mvR"
   },
   "outputs": [],
   "source": [
    "predictions_valid=clf2.predict(cv_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "j_K2fWx8wz-B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1633397616204,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "j_K2fWx8wz-B",
    "outputId": "05be68c3-5380-44f3-cfc7-f841d93da4d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Predicciones')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(labels_val, predictions_valid)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.xlabel(\"Valores Reales\")\n",
    "plt.ylabel(\"Predicciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pxH7_cgpHjG3",
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1633398475737,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "pxH7_cgpHjG3"
   },
   "outputs": [],
   "source": [
    "def get_metrics(Y_valid, Y_valid_p):\n",
    "  valid_metrics = []\n",
    "  \n",
    "  matriz_conf_valid = metrics.confusion_matrix(Y_valid, Y_valid_p)\n",
    "  sn.heatmap(matriz_conf_valid,annot=True,cmap='Blues')\n",
    "\n",
    "  #accuracy\n",
    "  valid_metrics.append(metrics.accuracy_score(Y_valid, Y_valid_p))\n",
    "  #precision\n",
    "  valid_metrics.append(metrics.precision_score(Y_valid, Y_valid_p, average='macro'))\n",
    "  #recall\n",
    "  valid_metrics.append(metrics.recall_score(Y_valid, Y_valid_p, average='macro'))\n",
    "  #f1-score\n",
    "  valid_metrics.append(metrics.f1_score(Y_valid, Y_valid_p, average='macro'))\n",
    "\n",
    "  metrics_valid = pd.DataFrame(valid_metrics, columns = ['Valores'] ,index = ['Accuracy','Precision','Recall','F1-score'])\n",
    "  \n",
    "  return metrics_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "RZ55wafcH6Yq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1633398478271,
     "user": {
      "displayName": "MARTINA BUNGE",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06668125805870524406"
     },
     "user_tz": 180
    },
    "id": "RZ55wafcH6Yq",
    "outputId": "7f76d2dc-28c7-47dc-8888-3d9ba7083d60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.667649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.667796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.667391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.667356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Valores\n",
       "Accuracy   0.667649\n",
       "Precision  0.667796\n",
       "Recall     0.667391\n",
       "F1-score   0.667356"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_valid = get_metrics(labels_val, predictions_valid)\n",
    "metrics_valid"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Qm-YVqXEHLva",
    "uEMUy6KTUqD-",
    "SBri-ajqmRj0"
   ],
   "name": " TP1 MLP.ipynb",
   "provenance": [
    {
     "file_id": "11CbBsLeW9C6Qucg44ajHpTlf4EMlH50n",
     "timestamp": 1633140394847
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:CNN_clases]",
   "language": "python",
   "name": "conda-env-CNN_clases-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
